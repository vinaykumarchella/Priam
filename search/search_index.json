{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"latest/","text":"Table Of Contents TL;DR; Requirements Compatibility Installation Management Tasks Token Management Cassandra Tuning Cassandra REST API Backups Restore Compaction Flush Health Configuration Metrics Contributions Presentations FAQ Authors TL;DR; Priam is a process/tool that runs alongside [Apache Cassandra] (http://cassandra.apache.org), a highly available, column-oriented database. Priam automates following tasks: Backup and recovery (Complete and incremental) Token management Seed discovery Configuration The name 'Priam' refers to the King of Troy in Greek mythology, who was the father of Cassandra. Priam is actively developed and used at Netflix since mid 2011. Features Token management using SimpleDB Support multi-region Cassandra deployment in AWS via public IP. Automated security group update in multi-region environment. Backup SSTables from local ephemeral disks to S3. Uses Snappy compression to compress backup data on the fly. Backup throttling Pluggable modules for future enhancements (support for multiple data storage). REST APIs for backup/restore and other operations REST APIs for validating backups. Monitor health of Cassandra and auto-remediate common issues. Requirements Cloud support: AWS only Requires deployment of EC2 Instances behind an Auto Scaling Group(ASG). Ideally one ASG per datacenter. Supports one token per EC2 instance (no support for vnodes yet) Compatibility |Priam Branch|Cassandra Version |Description| Javadoc | :-----------:| :-----------------: | :--------- | | 4.x |C 4.x | Alpha: Currently it supports Apache C 4.x| link | 3.11 | C 3.x | Currently it supports Apache C 3.x | link | 3.x | C 2.1.x | Any minor version of Apache C 2.1.x and DSE | link Authors Arun Agrawal @arunagrawal84 Joseph Lynch @jolynch Vinay Chella @vinaykumarchella License Copyright 2011-2018 Netflix, Inc. Licensed under the Apache License, Version 2.0 (the \u201cLicense\u201d); you may not use this file except in compliance with the License. You may obtain a copy of the License at (http://www.apache.org/licenses/LICENSE-2.0) Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \u201cAS IS\u201d BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. A Netflix Original Production Netflix OSS | Tech Blog | Twitter @NetflixOSS | Jobs","title":"Getting started."},{"location":"latest/#table-of-contents","text":"","title":"Table Of Contents"},{"location":"latest/#tldr","text":"Requirements Compatibility","title":"TL;DR;"},{"location":"latest/#installation","text":"","title":"Installation"},{"location":"latest/#management-tasks","text":"Token Management Cassandra Tuning Cassandra REST API Backups Restore Compaction Flush Health Configuration Metrics","title":"Management Tasks"},{"location":"latest/#contributions","text":"","title":"Contributions"},{"location":"latest/#presentations","text":"","title":"Presentations"},{"location":"latest/#faq","text":"","title":"FAQ"},{"location":"latest/#authors","text":"","title":"Authors"},{"location":"latest/#tldr_1","text":"Priam is a process/tool that runs alongside [Apache Cassandra] (http://cassandra.apache.org), a highly available, column-oriented database. Priam automates following tasks: Backup and recovery (Complete and incremental) Token management Seed discovery Configuration The name 'Priam' refers to the King of Troy in Greek mythology, who was the father of Cassandra. Priam is actively developed and used at Netflix since mid 2011.","title":"TL;DR;"},{"location":"latest/#features","text":"Token management using SimpleDB Support multi-region Cassandra deployment in AWS via public IP. Automated security group update in multi-region environment. Backup SSTables from local ephemeral disks to S3. Uses Snappy compression to compress backup data on the fly. Backup throttling Pluggable modules for future enhancements (support for multiple data storage). REST APIs for backup/restore and other operations REST APIs for validating backups. Monitor health of Cassandra and auto-remediate common issues.","title":"Features"},{"location":"latest/#requirements","text":"Cloud support: AWS only Requires deployment of EC2 Instances behind an Auto Scaling Group(ASG). Ideally one ASG per datacenter. Supports one token per EC2 instance (no support for vnodes yet)","title":"Requirements"},{"location":"latest/#compatibility","text":"|Priam Branch|Cassandra Version |Description| Javadoc | :-----------:| :-----------------: | :--------- | | 4.x |C 4.x | Alpha: Currently it supports Apache C 4.x| link | 3.11 | C 3.x | Currently it supports Apache C 3.x | link | 3.x | C 2.1.x | Any minor version of Apache C 2.1.x and DSE | link","title":"Compatibility"},{"location":"latest/#authors_1","text":"Arun Agrawal @arunagrawal84 Joseph Lynch @jolynch Vinay Chella @vinaykumarchella","title":"Authors"},{"location":"latest/#license","text":"Copyright 2011-2018 Netflix, Inc. Licensed under the Apache License, Version 2.0 (the \u201cLicense\u201d); you may not use this file except in compliance with the License. You may obtain a copy of the License at (http://www.apache.org/licenses/LICENSE-2.0) Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \u201cAS IS\u201d BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. A Netflix Original Production Netflix OSS | Tech Blog | Twitter @NetflixOSS | Jobs","title":"License"},{"location":"latest/faq/enable_auth/","text":"Enabling Authentication and Authorization on Cassandra By default, Priam does NOT enable authentication or authorization to Cassandra cluster. Any running Cassandra cluster can be converted to authenticated and/or authorized cluster. Make sure following parameters are either commented or do not exist in cassandra.yaml before enabling authentication / authorization on Cassandra, if not done will generate huge schema differences. auth_replication_strategy auth_replication_options replication_factor Set Cassandra in transitional mode by setting the following properties: priam.authenticator = com.datastax.bdp.cassandra.auth.TransitionalAuthenticator priam.authorizer = com.datastax.bdp.cassandra.auth.TransitionalAuthorizer This is important as it will allow existing clients to connect to Cassandra while we make all the changes. Re-start Priam and C* on a node and ensure that the system_auth KS is created by logging using the default cassandra user/password. ```sql cqlsh -u cassandra -p cassandra cqlsh use system_auth ; cqlsh:system_auth desc TABLEs credentials permissions users cqlsh:system_auth select * from system_auth.users ; name | super -----------+------- cassandra | True ``` Alter the system_auth KS to all the DC's your cluster is in. For example : Alter KEYSPACE system_auth WITH replication = { 'class': 'NetworkTopologyStrategy', 'us-east': '3', 'us-east-2': '3'}; Create the users and alter the default password for user \" cassandra \". Alter user cassandra with password \u2018XYZ\u2019 CREATE USER appuser1 WITH PASSWORD 'password'; Repair the keyspace to ensure data is propogated to all the instances. nodetool repair system_auth Change the authenticator and authorizer property in Priam to following values: priam.auto.bootstrap = true priam.authenticator = org.apache.cassandra.auth.PasswordAuthenticator priam.authorizer = org.apache.cassandra.auth.CassandraAuthorizer Perform a rolling restart of Priam and Cassandra on all the instances.","title":"Enabling Authentication and Authorization on Cassandra"},{"location":"latest/faq/enable_auth/#enabling-authentication-and-authorization-on-cassandra","text":"By default, Priam does NOT enable authentication or authorization to Cassandra cluster. Any running Cassandra cluster can be converted to authenticated and/or authorized cluster. Make sure following parameters are either commented or do not exist in cassandra.yaml before enabling authentication / authorization on Cassandra, if not done will generate huge schema differences. auth_replication_strategy auth_replication_options replication_factor Set Cassandra in transitional mode by setting the following properties: priam.authenticator = com.datastax.bdp.cassandra.auth.TransitionalAuthenticator priam.authorizer = com.datastax.bdp.cassandra.auth.TransitionalAuthorizer This is important as it will allow existing clients to connect to Cassandra while we make all the changes. Re-start Priam and C* on a node and ensure that the system_auth KS is created by logging using the default cassandra user/password. ```sql cqlsh -u cassandra -p cassandra cqlsh use system_auth ; cqlsh:system_auth desc TABLEs credentials permissions users cqlsh:system_auth select * from system_auth.users ; name | super -----------+------- cassandra | True ``` Alter the system_auth KS to all the DC's your cluster is in. For example : Alter KEYSPACE system_auth WITH replication = { 'class': 'NetworkTopologyStrategy', 'us-east': '3', 'us-east-2': '3'}; Create the users and alter the default password for user \" cassandra \". Alter user cassandra with password \u2018XYZ\u2019 CREATE USER appuser1 WITH PASSWORD 'password'; Repair the keyspace to ensure data is propogated to all the instances. nodetool repair system_auth Change the authenticator and authorizer property in Priam to following values: priam.auto.bootstrap = true priam.authenticator = org.apache.cassandra.auth.PasswordAuthenticator priam.authorizer = org.apache.cassandra.auth.CassandraAuthorizer Perform a rolling restart of Priam and Cassandra on all the instances.","title":"Enabling Authentication and Authorization on Cassandra"},{"location":"latest/faq/expanding_cassandra/","text":"Expanding Cassandra Cluster Priam currently only supports one token per instance paradigm. This allows for a Cassandra cluster to be only doubled in number of instances, to increase the capacity. The idea behind doubling the size the Cassandra cluster is we expect all the instances to take equal load . Doubling the existing cluster Ensure that Cassandra cluster is healthy and all the Cassandra instances are UP and serving traffic. Run a diagnostic check on this cluster by following these steps: Take a backup of the token metadata for this cluster. Ensure that you have a backup of this cluster in the remote file system and it is valid. Refer to backups to see how to validate the backups. Check for any host id collisions by calling nodetool info on all the Cassandra instances. Execute a double ring command from any ONE priam instance. This will double the entries of tokens in the token data store. Note : Sometimes this call may take up to 5 minutes to execute. Do NOT run this command again. Ensure that token data store has double the tokens and take a backup of this doubled entries. Now add one instance to the ASG and wait for it to stream completely from the neighbors. Repeat this process till the size of the ASG has been doubled. Repeat above step for all the ASG's in the region. Once all the nodes have streamed and joined the ring, run the nodetool cleanup on old instances. This will delete the data from old instances which they do not own anymore. Expanding to a new region for an existing cluster Ensure that priam.create.new.token is true for the region where we want to exapnd. Create new security groups, IAM Roles, S3 buckets and ASG's for the cluster. Ensure that IAM Role has permission to access the S3 buckets. Ensure that Cassandra cluster is healthy and all the Cassandra instances are UP and serving traffic. Add the required number of instances in the ASG to match other ASG from other region. Once they join the ring, disable the priam.create.new.token by setting this to false . Expand the keyspace definition to include this new region. Example: sql cqlsh DESC KEYSPACE user_keyspace; CREATE KEYSPACE user_keyspace WITH replication = {'class': 'NetworkTopologyStrategy', 'us-east': '3'} AND durable_writes = true; cqlsh Alter KEYSPACE user_keyspace WITH replication = { 'class': 'NetworkTopologyStrategy', 'us-east': '3', 'us-east-2': '3'}; Run nodetool rebuild on all the instances. Recommendation is to run this on one ASG first, ensure it is finished and then other ASG. This is to avoid huge spike in cross-region streaming between existing Cassandra instances (serving live traffic) and these new instances. Run nodetool repair on the entire fleet before declaring newly added region available.","title":"Expanding Cassandra Cluster"},{"location":"latest/faq/expanding_cassandra/#expanding-cassandra-cluster","text":"Priam currently only supports one token per instance paradigm. This allows for a Cassandra cluster to be only doubled in number of instances, to increase the capacity. The idea behind doubling the size the Cassandra cluster is we expect all the instances to take equal load .","title":"Expanding Cassandra Cluster"},{"location":"latest/faq/expanding_cassandra/#doubling-the-existing-cluster","text":"Ensure that Cassandra cluster is healthy and all the Cassandra instances are UP and serving traffic. Run a diagnostic check on this cluster by following these steps: Take a backup of the token metadata for this cluster. Ensure that you have a backup of this cluster in the remote file system and it is valid. Refer to backups to see how to validate the backups. Check for any host id collisions by calling nodetool info on all the Cassandra instances. Execute a double ring command from any ONE priam instance. This will double the entries of tokens in the token data store. Note : Sometimes this call may take up to 5 minutes to execute. Do NOT run this command again. Ensure that token data store has double the tokens and take a backup of this doubled entries. Now add one instance to the ASG and wait for it to stream completely from the neighbors. Repeat this process till the size of the ASG has been doubled. Repeat above step for all the ASG's in the region. Once all the nodes have streamed and joined the ring, run the nodetool cleanup on old instances. This will delete the data from old instances which they do not own anymore.","title":"Doubling the existing cluster"},{"location":"latest/faq/expanding_cassandra/#expanding-to-a-new-region-for-an-existing-cluster","text":"Ensure that priam.create.new.token is true for the region where we want to exapnd. Create new security groups, IAM Roles, S3 buckets and ASG's for the cluster. Ensure that IAM Role has permission to access the S3 buckets. Ensure that Cassandra cluster is healthy and all the Cassandra instances are UP and serving traffic. Add the required number of instances in the ASG to match other ASG from other region. Once they join the ring, disable the priam.create.new.token by setting this to false . Expand the keyspace definition to include this new region. Example: sql cqlsh DESC KEYSPACE user_keyspace; CREATE KEYSPACE user_keyspace WITH replication = {'class': 'NetworkTopologyStrategy', 'us-east': '3'} AND durable_writes = true; cqlsh Alter KEYSPACE user_keyspace WITH replication = { 'class': 'NetworkTopologyStrategy', 'us-east': '3', 'us-east-2': '3'}; Run nodetool rebuild on all the instances. Recommendation is to run this on one ASG first, ensure it is finished and then other ASG. This is to avoid huge spike in cross-region streaming between existing Cassandra instances (serving live traffic) and these new instances. Run nodetool repair on the entire fleet before declaring newly added region available.","title":"Expanding to a new region for an existing cluster"},{"location":"latest/faq/faq/","text":"FAQ How do I enable authentication and/or authorization on already running Cassandra cluster If you already have running cassandra cluster with Priam, you can follow the steps mentioned here . Increasing Cassandra cluster There are 3 ways to increase the Cassandra cluster capacity: 1. Instance Upgrade: With this you replace the instance types of the Cassandra cluster by more/less powerful instances, one by one. Note : This does not increase the number of coordinator nodes. 2. Doubling the cassandra cluster : This will double the number of instances in your Cassandra cluster. This is usually preferred way to go (if possible) as this truly doubles the capacity of the Cassandra cluster by providing more co-ordinates nodes and gives more JVM's. 3. Add a new region to existing Cassandra cluster.","title":"FAQ"},{"location":"latest/faq/faq/#faq","text":"","title":"FAQ"},{"location":"latest/faq/faq/#how-do-i-enable-authentication-andor-authorization-on-already-running-cassandra-cluster","text":"If you already have running cassandra cluster with Priam, you can follow the steps mentioned here .","title":"How do I enable authentication and/or authorization on already running Cassandra cluster"},{"location":"latest/faq/faq/#increasing-cassandra-cluster","text":"There are 3 ways to increase the Cassandra cluster capacity: 1. Instance Upgrade: With this you replace the instance types of the Cassandra cluster by more/less powerful instances, one by one. Note : This does not increase the number of coordinator nodes. 2. Doubling the cassandra cluster : This will double the number of instances in your Cassandra cluster. This is usually preferred way to go (if possible) as this truly doubles the capacity of the Cassandra cluster by providing more co-ordinates nodes and gives more JVM's. 3. Add a new region to existing Cassandra cluster.","title":"Increasing Cassandra cluster"},{"location":"latest/mgmt/backups/","text":"Backups Priam supports both snapshot and incremental backups for Cassandra SSTable files and uses S3 to save these files. Backup file path To identify backup files and to avoid collision, Priam organizes the files in S3 by including time, keyspace name, token, date, DC/region and cluster name. Here is the general format: App Prefix / Region or DC / Cluster name / Token / Date Time / File type / Keyspace / FileName Here are valid file types (refer AbstractBackupPath.BackupFileType ): SNAP - Snapshot file META - Meta file for all snapshot files SST - Incremental SSTable file Here is a sample snapshot file in S3: test_backup/eu-west-1/cass_test/37809151880104273718152734159458104939/201202142346/SNAP/MyKeyspace/MyCF-g-265-Data.db Multipart upload Priam leverages the multipart upload feature of S3. This helps in uploading large files in parallel. Each file is chunked into several parts and each part is uploaded in parallel. Compression Priam uses snappy compression to compress data files. Each file is chunked and compressed on the fly. Throttling Throttling of uploads helps reduce disk IO and network IO as well. With Priam properties, you can set the Mb/s which are read from the disk. SNS Notifications Priam can send SNS Notifications, pre and post upload of any file to S3. This allows a cleaner integration with external service depending on backups which are about to be uploaded. Async Uploads Priam allows user to configure if they wish to do parallel uploads to remote file system for snapshots and incrementals. Doing parallel uploads makes your backup faster but may use the bandwidth of the instance and thus starve Cassandra. Bandwidth used by backups can be controlled by throttling them. This should be carefully reviewed based on your instance capabilities. Priam by default does NOT allow async uploads, though our suggestion is to enable them on few instances and see the performance and then tune. In our internal testing, we have hardly found Cassandra to be starved by bandwidth usage (even during peak). Configuration priam.s3.bucket : This is the default S3 location where all backup files will be uploaded to. E.g. s3_bucket_region . Default: cassandra-archive priam.upload.throttle : This allows backup/incremental's to be throttled so they don't end up taking all the bandwidth from Cassandra. Note: try to schedule full snapshot during off-peak time. Tweak this only if required else your snapshot would starve. Default: MAX_INT_VALUE . priam.backup.notification.topic.arn : Amazon Resource Name for the SNS service where notifications need to be sent. This assumes that all the topics are created and the instance has permission to send SNS messages. Disabled if the value is null or empty. Default: None . priam.backup.chunksizemb : Size of the file in MB above which Priam will try to use multi-part uploads. Note that chunk size of the file being uploaded is as defined by user only if total parts to be uploaded (based on file size) will not exceed 10000 (max limit from AWS). If file is bigger than 10000 * configured chunk size, Priam will adjust the chunk size to ensure it can upload the file. Default: 10 MB priam.backup.queue.size : Queue size to be used for backup uploads. Note that once queue is full, we would wait for priam.upload.timeout to add any new item before declining the request and throwing exception. Default: 100,000. priam.backup.threads : The number of backup threads to be used to upload files to S3. Default: 2 priam.upload.timeout : Uploads are scheduled in priam.backup.queue.size . If queue is full then we wait for this time for the queue to have an entry available for queueing the current task. Default: 2 minutes. Snapshot or complete backup Priam leverages Cassandra's snapshot feature to have an eventually consistent backup. Cassandra's snapshot feature flushes data to disk and hard links all SSTable files into a snapshot directory. These files are then picked up by Priam and uploaded to S3. Although snapshotting across the cluster is not guaranteed to produce a consistent backup of the cluster, consistency is resumed upon restore by Cassandra and running repairs. Priam uses Quartz to schedule all tasks. Snapshot backups are run as a recurring task. They can also be triggered via REST API (refer API section), which is useful during upgrades or maintenance operations. Snapshots are run on a CRON for the entire cluster, at a specific time, ideally during non-peak hours. Priam's backup.hour or backup.cron property allows you to set daily snapshot time (refer properties). The snapshot backup orchestrates invoking of Cassandra snapshot JMX command, uploading files to S3 and cleaning up the directory. meta.json All SSTable files are uploaded individually to S3 with built-in retries on failure. Upon completion, the meta file ( meta.json ) is uploaded which contains a reference to all files that belong to the snapshot. This is then used for validation during restore. Backup Status Management Priam by default stores the status of all the snapshot. This is useful to determine if the snapshot at a given Instant was successful. It has support to store status of multiple snapshots for a given date. The default binding is to store these details to a local file configured via priam.backup.status.location . Validation of Snapshot Priam can download the meta.json for a given snapshot, parse it and then validate the backup by ensuring that all the files listed in file are available on remote file system. This can be used to verify that no file was missed during snapshot. Snapshot Configuration priam.backup.schedule.type : This allows you to choose between 2 supported schedule types (CRON or HOUR) for backup. The default value is HOUR . CRON : This allows backup to run on CRON and it expects a valid value of priam.backup.cron to be there. If not, priam will not start and fail fast. Deprecated : HOUR : This allows backup to run on a daily basis at a given hour. It expects a valid value of priam.backup.hour to be there. If not, priam will not start and fail fast. Deprecated : priam.backup.hour : This allows backup to run on a daily basis at a given hour. If the value is -1 , it means snapshot backups and incremental are disabled. Default value: 12 priam.backup.cron : This allows backups to be run on CRON. Example: you want to run a backup once a week. Value needs to be a valid CRON expression. To disable backup, use the value of -1 . The default value is to backup at 12 . priam.snapshot.cf.include : Column Family(ies), comma delimited, to include for snapshot. If no override exists, all keyspaces/cf's will be backed up to remote file system. The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Snapshot exclude list is applied first to exclude CF/keyspace and then snapshot include list is applied to include the CF's/keyspaces. Default: None priam.snapshot.cf.exclude : Column Family(ies), comma delimited, to ignore while doing snapshot. The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Snapshot exclude list is applied first to exclude CF/keyspace and then snapshot include list is applied to include the CF's/keyspaces. Default: None priam.backup.status.location : The absolute path to store the backup status on disk. Default: data file location /backup.status . priam.async.snapshot : This decides if snapshot files should be uploaded to the remote file system in async fashion. This will allow snapshot to use the priam.backup.threads to do parallel uploads. Default: false . API Execute Snapshot http://localhost:8080/Priam/REST/v1/backup/do_snapshot This executes a one time snapshot on this instance and starts uploading the files to remote file system. Output: { ok } ``` ### Backup Status ```http://localhost:8080/Priam/REST/v1/backup/status``` Get the status of the last known backup. If priam is restarted, it will always show `DONE`. **Output:** ```json { SnapshotStatus : [DONE|ERROR|RUNNING|NOT_APPLICABLE] } Backup Status for a date http://localhost:8080/Priam/REST/v1/backup/status/{date} Determines the status of a snapshot for a date. If there was at least one successful snapshot for the date, snapshot for the date is considered completed. Parameters: * {date}: Required: Date of the snapshot to check in the format of yyyyMMdd . Output: For success: { Snapshotstatus :true, token : token_value , starttime : [yyyyMMddHHmm] , completetime : [yyyyMMddHHmm] } For failure: { Snapshotstatus :true, token : token_value } List all snapshots http://localhost:8080/Priam/REST/v1/backup/status/{date}/snapshots List all the snapshot executed for a date. Parameters: * {date}: Required: Date of the snapshot to check in the format of yyyyMMdd . Output: { Snapshots :[ yyyyMMddHHmm , yyyyMMddHHmm ]} Validate snapshot http://localhost:8080/Priam/REST/v1/backup/validate/snapshot/{daterange} Determines the validity of the backup by Downloading meta.json file Listing of the backup directory Find the missing or extra files in backup location. This by default takes the latest snapshot of the application. One can provide exact hour and min to check specific backup. Note : This is an expensive call (money and time) as it calls list on the remote file system, thus should be used with caution. Parameters: * daterange : Optional: This is a comma separated start time and end time for the snapshot in the format of yyyyMMddHHmm or yyyyMMdd . If no value is provided or a value of default is provided then it takes start time as (current time - 1 day) and end time as current time. Output: { inputStartDate : [yyyyMMddHHmm] , inputEndDate : [yyyyMMddHHmm] , snapshotAvailable :true, valid :true, backupFileListAvailable :true, metaFileFound :true, selectedDate : [yyyyMMdd] , snapshotTime : [yyyyMMddHHmm] , filesInMetaOnly :[ ], filesInS3Only :[ file1 ], filesMatched :[ file1 , file2 ] } List the backup files http://localhost:8080/Priam/REST/v1/backup/list/{daterange} List all the files in the remote file system for the given daterange. Note : This is an expensive call (money and time) as it calls list on the remote file system, thus should be used with caution. Parameters: * daterange : Optional: This is a comma separated start time and end time for the snapshot in the format of yyyyMMddHHmm or yyyyMMdd . If no value is provided or a value of default is provided then it takes start time as (current time - 1 day) and end time as current time. Output: { files : [ { bucket : remote_file_system , filename : file , app : app_name , region : region , token : token , ts : [yyyyMMddHHmm] , instance_id : instance_id , uploaded_ts : [yyyyMMddHHmm] } ], num_files : no_of_files } Incremental backup When incremental backups are enabled in Cassandra, hard links are created for all new SSTables created in the incremental backup directory. Since SSTables are immutable files they can be safely copied to an external source. Priam scans this directory frequently for incremental SSTable files and uploads to S3. Incremental Configuration priam.backup.incremental.enable : This allows the incremental backups to be uploaded to S3. By default every 10 seconds, Priam will try to upload any new files flushed/compacted by Cassandra to disk. Default: true priam.incremental.cf.include : Column Family(ies), comma delimited, to include for incremental backups. If no override exists, all keyspaces/cf's will be backed up to remote file system. The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Incremental exclude list is applied first to exclude CF/keyspace and then incremental include list is applied to include the CF's/keyspaces. Default: None priam.incremental.cf.exclude : Column Family(ies), comma delimited, to ignore while doing incremental backup. The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Incremental exclude list is applied first to exclude CF/keyspace and then incremental include list is applied to include the CF's/keyspaces. Default: None priam.async.incremental : Allow upload of incremental's in parallel using multiple threads. Note that this will take more bandwidth of your cluster and thus should be used with caution. It may be required when you do repair your instance primary token range using subrange repair creating a lot of small files during the process. Default: false API http://localhost:8080/Priam/REST/v1/backup/incremental_backup Enable the incremental backup on this instance. Note : This call does not change the value of the property priam.backup.incremental.enable Output: { ok } Commit log Configuration priam.clbackup.enabled : This allows the backup of the commit logs from Cassandra to the backup location. The default value to check for new commit log is 1 min. Default: false Encryption of Backup/Restore Backups can be encrypted by Priam. Priam can also restore from the encrypted backups for disaster recovery. Note that encryption/decryption is generally CPU and time-intensive process. While uploading the file, it would be first compressed and then encrypted. The reverse of that happens when downloading the file i.e. decrypt and then decompress. Priam uses PGP as the encryption / decryption cryptography algorithm. Other algorithm can be implemented via interface IFileCryptography. *Note: Pgp uses a passphrase to encrypt your private key on your node. See (http://www.pgpi.org/doc/pgpintro/), section \u201cwhat is a passphrase\u201d for details. Configuration priam.encrypted.backup.enabled : Allow encryption while uploading of the snapshot, incremental and commit logs. Default: false priam.pgp.password.phrase : The passphrase used by the cryptography algorithm to encrypt/decrypt. By default, it is expected that this value will be encrypted using open encrypt. Default: None . priam.private.key.location : The location on disk of the private key used by the cryptography algorithm. priam.pgp.pubkey.file.location : The location on disk of the public key used by the cryptography algorithm.","title":"Backups"},{"location":"latest/mgmt/backups/#backups","text":"Priam supports both snapshot and incremental backups for Cassandra SSTable files and uses S3 to save these files.","title":"Backups"},{"location":"latest/mgmt/backups/#backup-file-path","text":"To identify backup files and to avoid collision, Priam organizes the files in S3 by including time, keyspace name, token, date, DC/region and cluster name. Here is the general format: App Prefix / Region or DC / Cluster name / Token / Date Time / File type / Keyspace / FileName Here are valid file types (refer AbstractBackupPath.BackupFileType ): SNAP - Snapshot file META - Meta file for all snapshot files SST - Incremental SSTable file Here is a sample snapshot file in S3: test_backup/eu-west-1/cass_test/37809151880104273718152734159458104939/201202142346/SNAP/MyKeyspace/MyCF-g-265-Data.db","title":"Backup file path"},{"location":"latest/mgmt/backups/#multipart-upload","text":"Priam leverages the multipart upload feature of S3. This helps in uploading large files in parallel. Each file is chunked into several parts and each part is uploaded in parallel.","title":"Multipart upload"},{"location":"latest/mgmt/backups/#compression","text":"Priam uses snappy compression to compress data files. Each file is chunked and compressed on the fly.","title":"Compression"},{"location":"latest/mgmt/backups/#throttling","text":"Throttling of uploads helps reduce disk IO and network IO as well. With Priam properties, you can set the Mb/s which are read from the disk.","title":"Throttling"},{"location":"latest/mgmt/backups/#sns-notifications","text":"Priam can send SNS Notifications, pre and post upload of any file to S3. This allows a cleaner integration with external service depending on backups which are about to be uploaded.","title":"SNS Notifications"},{"location":"latest/mgmt/backups/#async-uploads","text":"Priam allows user to configure if they wish to do parallel uploads to remote file system for snapshots and incrementals. Doing parallel uploads makes your backup faster but may use the bandwidth of the instance and thus starve Cassandra. Bandwidth used by backups can be controlled by throttling them. This should be carefully reviewed based on your instance capabilities. Priam by default does NOT allow async uploads, though our suggestion is to enable them on few instances and see the performance and then tune. In our internal testing, we have hardly found Cassandra to be starved by bandwidth usage (even during peak).","title":"Async Uploads"},{"location":"latest/mgmt/backups/#configuration","text":"priam.s3.bucket : This is the default S3 location where all backup files will be uploaded to. E.g. s3_bucket_region . Default: cassandra-archive priam.upload.throttle : This allows backup/incremental's to be throttled so they don't end up taking all the bandwidth from Cassandra. Note: try to schedule full snapshot during off-peak time. Tweak this only if required else your snapshot would starve. Default: MAX_INT_VALUE . priam.backup.notification.topic.arn : Amazon Resource Name for the SNS service where notifications need to be sent. This assumes that all the topics are created and the instance has permission to send SNS messages. Disabled if the value is null or empty. Default: None . priam.backup.chunksizemb : Size of the file in MB above which Priam will try to use multi-part uploads. Note that chunk size of the file being uploaded is as defined by user only if total parts to be uploaded (based on file size) will not exceed 10000 (max limit from AWS). If file is bigger than 10000 * configured chunk size, Priam will adjust the chunk size to ensure it can upload the file. Default: 10 MB priam.backup.queue.size : Queue size to be used for backup uploads. Note that once queue is full, we would wait for priam.upload.timeout to add any new item before declining the request and throwing exception. Default: 100,000. priam.backup.threads : The number of backup threads to be used to upload files to S3. Default: 2 priam.upload.timeout : Uploads are scheduled in priam.backup.queue.size . If queue is full then we wait for this time for the queue to have an entry available for queueing the current task. Default: 2 minutes.","title":"Configuration"},{"location":"latest/mgmt/backups/#snapshot-or-complete-backup","text":"Priam leverages Cassandra's snapshot feature to have an eventually consistent backup. Cassandra's snapshot feature flushes data to disk and hard links all SSTable files into a snapshot directory. These files are then picked up by Priam and uploaded to S3. Although snapshotting across the cluster is not guaranteed to produce a consistent backup of the cluster, consistency is resumed upon restore by Cassandra and running repairs. Priam uses Quartz to schedule all tasks. Snapshot backups are run as a recurring task. They can also be triggered via REST API (refer API section), which is useful during upgrades or maintenance operations. Snapshots are run on a CRON for the entire cluster, at a specific time, ideally during non-peak hours. Priam's backup.hour or backup.cron property allows you to set daily snapshot time (refer properties). The snapshot backup orchestrates invoking of Cassandra snapshot JMX command, uploading files to S3 and cleaning up the directory.","title":"Snapshot or complete backup"},{"location":"latest/mgmt/backups/#metajson","text":"All SSTable files are uploaded individually to S3 with built-in retries on failure. Upon completion, the meta file ( meta.json ) is uploaded which contains a reference to all files that belong to the snapshot. This is then used for validation during restore.","title":"meta.json"},{"location":"latest/mgmt/backups/#backup-status-management","text":"Priam by default stores the status of all the snapshot. This is useful to determine if the snapshot at a given Instant was successful. It has support to store status of multiple snapshots for a given date. The default binding is to store these details to a local file configured via priam.backup.status.location .","title":"Backup Status Management"},{"location":"latest/mgmt/backups/#validation-of-snapshot","text":"Priam can download the meta.json for a given snapshot, parse it and then validate the backup by ensuring that all the files listed in file are available on remote file system. This can be used to verify that no file was missed during snapshot.","title":"Validation of Snapshot"},{"location":"latest/mgmt/backups/#snapshot-configuration","text":"priam.backup.schedule.type : This allows you to choose between 2 supported schedule types (CRON or HOUR) for backup. The default value is HOUR . CRON : This allows backup to run on CRON and it expects a valid value of priam.backup.cron to be there. If not, priam will not start and fail fast. Deprecated : HOUR : This allows backup to run on a daily basis at a given hour. It expects a valid value of priam.backup.hour to be there. If not, priam will not start and fail fast. Deprecated : priam.backup.hour : This allows backup to run on a daily basis at a given hour. If the value is -1 , it means snapshot backups and incremental are disabled. Default value: 12 priam.backup.cron : This allows backups to be run on CRON. Example: you want to run a backup once a week. Value needs to be a valid CRON expression. To disable backup, use the value of -1 . The default value is to backup at 12 . priam.snapshot.cf.include : Column Family(ies), comma delimited, to include for snapshot. If no override exists, all keyspaces/cf's will be backed up to remote file system. The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Snapshot exclude list is applied first to exclude CF/keyspace and then snapshot include list is applied to include the CF's/keyspaces. Default: None priam.snapshot.cf.exclude : Column Family(ies), comma delimited, to ignore while doing snapshot. The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Snapshot exclude list is applied first to exclude CF/keyspace and then snapshot include list is applied to include the CF's/keyspaces. Default: None priam.backup.status.location : The absolute path to store the backup status on disk. Default: data file location /backup.status . priam.async.snapshot : This decides if snapshot files should be uploaded to the remote file system in async fashion. This will allow snapshot to use the priam.backup.threads to do parallel uploads. Default: false .","title":"Snapshot Configuration"},{"location":"latest/mgmt/backups/#api","text":"","title":"API"},{"location":"latest/mgmt/backups/#execute-snapshot","text":"http://localhost:8080/Priam/REST/v1/backup/do_snapshot This executes a one time snapshot on this instance and starts uploading the files to remote file system. Output: { ok } ``` ### Backup Status ```http://localhost:8080/Priam/REST/v1/backup/status``` Get the status of the last known backup. If priam is restarted, it will always show `DONE`. **Output:** ```json { SnapshotStatus : [DONE|ERROR|RUNNING|NOT_APPLICABLE] }","title":"Execute Snapshot"},{"location":"latest/mgmt/backups/#backup-status-for-a-date","text":"http://localhost:8080/Priam/REST/v1/backup/status/{date} Determines the status of a snapshot for a date. If there was at least one successful snapshot for the date, snapshot for the date is considered completed. Parameters: * {date}: Required: Date of the snapshot to check in the format of yyyyMMdd . Output: For success: { Snapshotstatus :true, token : token_value , starttime : [yyyyMMddHHmm] , completetime : [yyyyMMddHHmm] } For failure: { Snapshotstatus :true, token : token_value }","title":"Backup Status for a date"},{"location":"latest/mgmt/backups/#list-all-snapshots","text":"http://localhost:8080/Priam/REST/v1/backup/status/{date}/snapshots List all the snapshot executed for a date. Parameters: * {date}: Required: Date of the snapshot to check in the format of yyyyMMdd . Output: { Snapshots :[ yyyyMMddHHmm , yyyyMMddHHmm ]}","title":"List all snapshots"},{"location":"latest/mgmt/backups/#validate-snapshot","text":"http://localhost:8080/Priam/REST/v1/backup/validate/snapshot/{daterange} Determines the validity of the backup by Downloading meta.json file Listing of the backup directory Find the missing or extra files in backup location. This by default takes the latest snapshot of the application. One can provide exact hour and min to check specific backup. Note : This is an expensive call (money and time) as it calls list on the remote file system, thus should be used with caution. Parameters: * daterange : Optional: This is a comma separated start time and end time for the snapshot in the format of yyyyMMddHHmm or yyyyMMdd . If no value is provided or a value of default is provided then it takes start time as (current time - 1 day) and end time as current time. Output: { inputStartDate : [yyyyMMddHHmm] , inputEndDate : [yyyyMMddHHmm] , snapshotAvailable :true, valid :true, backupFileListAvailable :true, metaFileFound :true, selectedDate : [yyyyMMdd] , snapshotTime : [yyyyMMddHHmm] , filesInMetaOnly :[ ], filesInS3Only :[ file1 ], filesMatched :[ file1 , file2 ] }","title":"Validate snapshot"},{"location":"latest/mgmt/backups/#list-the-backup-files","text":"http://localhost:8080/Priam/REST/v1/backup/list/{daterange} List all the files in the remote file system for the given daterange. Note : This is an expensive call (money and time) as it calls list on the remote file system, thus should be used with caution. Parameters: * daterange : Optional: This is a comma separated start time and end time for the snapshot in the format of yyyyMMddHHmm or yyyyMMdd . If no value is provided or a value of default is provided then it takes start time as (current time - 1 day) and end time as current time. Output: { files : [ { bucket : remote_file_system , filename : file , app : app_name , region : region , token : token , ts : [yyyyMMddHHmm] , instance_id : instance_id , uploaded_ts : [yyyyMMddHHmm] } ], num_files : no_of_files }","title":"List the backup files"},{"location":"latest/mgmt/backups/#incremental-backup","text":"When incremental backups are enabled in Cassandra, hard links are created for all new SSTables created in the incremental backup directory. Since SSTables are immutable files they can be safely copied to an external source. Priam scans this directory frequently for incremental SSTable files and uploads to S3.","title":"Incremental backup"},{"location":"latest/mgmt/backups/#incremental-configuration","text":"priam.backup.incremental.enable : This allows the incremental backups to be uploaded to S3. By default every 10 seconds, Priam will try to upload any new files flushed/compacted by Cassandra to disk. Default: true priam.incremental.cf.include : Column Family(ies), comma delimited, to include for incremental backups. If no override exists, all keyspaces/cf's will be backed up to remote file system. The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Incremental exclude list is applied first to exclude CF/keyspace and then incremental include list is applied to include the CF's/keyspaces. Default: None priam.incremental.cf.exclude : Column Family(ies), comma delimited, to ignore while doing incremental backup. The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Incremental exclude list is applied first to exclude CF/keyspace and then incremental include list is applied to include the CF's/keyspaces. Default: None priam.async.incremental : Allow upload of incremental's in parallel using multiple threads. Note that this will take more bandwidth of your cluster and thus should be used with caution. It may be required when you do repair your instance primary token range using subrange repair creating a lot of small files during the process. Default: false","title":"Incremental Configuration"},{"location":"latest/mgmt/backups/#api_1","text":"http://localhost:8080/Priam/REST/v1/backup/incremental_backup Enable the incremental backup on this instance. Note : This call does not change the value of the property priam.backup.incremental.enable Output: { ok }","title":"API"},{"location":"latest/mgmt/backups/#commit-log-configuration","text":"priam.clbackup.enabled : This allows the backup of the commit logs from Cassandra to the backup location. The default value to check for new commit log is 1 min. Default: false","title":"Commit log Configuration"},{"location":"latest/mgmt/backups/#encryption-of-backuprestore","text":"Backups can be encrypted by Priam. Priam can also restore from the encrypted backups for disaster recovery. Note that encryption/decryption is generally CPU and time-intensive process. While uploading the file, it would be first compressed and then encrypted. The reverse of that happens when downloading the file i.e. decrypt and then decompress. Priam uses PGP as the encryption / decryption cryptography algorithm. Other algorithm can be implemented via interface IFileCryptography. *Note: Pgp uses a passphrase to encrypt your private key on your node. See (http://www.pgpi.org/doc/pgpintro/), section \u201cwhat is a passphrase\u201d for details.","title":"Encryption of Backup/Restore"},{"location":"latest/mgmt/backups/#configuration_1","text":"priam.encrypted.backup.enabled : Allow encryption while uploading of the snapshot, incremental and commit logs. Default: false priam.pgp.password.phrase : The passphrase used by the cryptography algorithm to encrypt/decrypt. By default, it is expected that this value will be encrypted using open encrypt. Default: None . priam.private.key.location : The location on disk of the private key used by the cryptography algorithm. priam.pgp.pubkey.file.location : The location on disk of the public key used by the cryptography algorithm.","title":"Configuration"},{"location":"latest/mgmt/cassandrarestapi/","text":"Common prefix It will depend on how you deploy your application. In our case, we use it with following prefix: \"http://127.0.0.1:8080/Priam/REST\" E.g. to invoke get_token, which is under \"/v1/cassconfig\", the call is \"http://127.0.0.1:8080/Priam/REST/v1/cassconfig/get_token\" Cassandra Config related | API | Description | Query params | |/v1/cassconfig/get_seeds |Gets a list of seeds. One per zone/Rack | | |/v1/cassconfig/get_token |Get token for the node | | |/v1/cassconfig/is_replace_token |Returns true if this node is replace another node with the same token | | |/v1/cassconfig/double_ring |Double the ring | | Cassandra admin | API | Description | Query params | |/v1/cassadmin/start |Starts Cassandra process|| |/v1/cassadmin/stop |Stop Cassandra process | | Nodetool commands | API | Description | Query params | |/v1/cassadmin/info | Get info (nodetool info) in json format | | |/v1/cassadmin/partitioner | Get partitioner name | | |/v1/cassadmin/ring/KEYSPACE | Get ring (nodetool ring) in json format. | Provide a Keyspace parameter | |/v1/cassadmin/flush |flushes all keyspaces | | |/v1/cassadmin/compact | Run compaction | | |/v1/cassadmin/cleanup | Run cleanup | | |/v1/cassadmin/repair | Run repair (nodetool repair) | | |/v1/cassadmin/refresh?keyspaces= | |KEYSPACES: Comma seperated list of keyspaces | |/v1/cassadmin/version | Show release version | | |/v1/cassadmin/tpstats | Show Thread pool stats | | |/v1/cassadmin/compactionstats | Show Compaction stats | | |/v1/cassadmin/disablegossip | Disable gossip | | |/v1/cassadmin/enablegossip | Enable gossip | | |/v1/cassadmin/disablethrift | Disable Thrift | | |/v1/cassadmin/enablethrift | Enable Thrift | | |/v1/cassadmin/statusthrift | Show Thrift Status | | |/v1/cassadmin/gossipinfo | Show Gossip Info | | |/v1/cassadmin/netstats?host= | Show Net Stats | HOST (optional)| |/v1/cassadmin/move?token= | Move | Provide New Token | |/v1/cassadmin/scrub?keyspaces= cfnames= | Run Scrub |KEYSPACES,CFNAMES(optional) | |/v1/cassadmin/cfhistograms?keyspaces= cfnames= | Run CF Histogram |KEYSPACES,CFNAMES |","title":"Common prefix"},{"location":"latest/mgmt/cassandrarestapi/#common-prefix","text":"It will depend on how you deploy your application. In our case, we use it with following prefix: \"http://127.0.0.1:8080/Priam/REST\" E.g. to invoke get_token, which is under \"/v1/cassconfig\", the call is \"http://127.0.0.1:8080/Priam/REST/v1/cassconfig/get_token\"","title":"Common prefix"},{"location":"latest/mgmt/cassandrarestapi/#cassandra-config-related","text":"| API | Description | Query params | |/v1/cassconfig/get_seeds |Gets a list of seeds. One per zone/Rack | | |/v1/cassconfig/get_token |Get token for the node | | |/v1/cassconfig/is_replace_token |Returns true if this node is replace another node with the same token | | |/v1/cassconfig/double_ring |Double the ring | |","title":"Cassandra Config related"},{"location":"latest/mgmt/cassandrarestapi/#cassandra-admin","text":"| API | Description | Query params | |/v1/cassadmin/start |Starts Cassandra process|| |/v1/cassadmin/stop |Stop Cassandra process | |","title":"Cassandra admin"},{"location":"latest/mgmt/cassandrarestapi/#nodetool-commands","text":"| API | Description | Query params | |/v1/cassadmin/info | Get info (nodetool info) in json format | | |/v1/cassadmin/partitioner | Get partitioner name | | |/v1/cassadmin/ring/KEYSPACE | Get ring (nodetool ring) in json format. | Provide a Keyspace parameter | |/v1/cassadmin/flush |flushes all keyspaces | | |/v1/cassadmin/compact | Run compaction | | |/v1/cassadmin/cleanup | Run cleanup | | |/v1/cassadmin/repair | Run repair (nodetool repair) | | |/v1/cassadmin/refresh?keyspaces= | |KEYSPACES: Comma seperated list of keyspaces | |/v1/cassadmin/version | Show release version | | |/v1/cassadmin/tpstats | Show Thread pool stats | | |/v1/cassadmin/compactionstats | Show Compaction stats | | |/v1/cassadmin/disablegossip | Disable gossip | | |/v1/cassadmin/enablegossip | Enable gossip | | |/v1/cassadmin/disablethrift | Disable Thrift | | |/v1/cassadmin/enablethrift | Enable Thrift | | |/v1/cassadmin/statusthrift | Show Thrift Status | | |/v1/cassadmin/gossipinfo | Show Gossip Info | | |/v1/cassadmin/netstats?host= | Show Net Stats | HOST (optional)| |/v1/cassadmin/move?token= | Move | Provide New Token | |/v1/cassadmin/scrub?keyspaces= cfnames= | Run Scrub |KEYSPACES,CFNAMES(optional) | |/v1/cassadmin/cfhistograms?keyspaces= cfnames= | Run CF Histogram |KEYSPACES,CFNAMES |","title":"Nodetool commands"},{"location":"latest/mgmt/cassandratuning/","text":"Cassandra Tuning Priam tunes common cassandra configurations out of the box. Priam traditionally had support to tune Datastax Cassandra . With Datastax forking the Cassandra, Priam has stopped maintaining the DSE tuners since 3.11 branch of Priam. Note : DSE tuners will not be available going forward. Apache Cassandra 3.0.x (and above) have additional files that can be configured like jvm.options . Seed Provider Priam provides its own Seed Provider for Cassandra: NFSeedProvider . This allows Cassandra to get list of seed nodes from Priam at every startup. Priam sends an updated list of instances which can be used as seed for Cassandra to bootstrap . Priam manages the bootstrap process of cassandra based on: This is a new cluster Replacement of the instance Doubling of Cassandra cluster Restore mode. priam.seed.provider : Seed provider to be used to determine the seed nodes for an instance to bootstrap. Default: com.netflix.priam.cassandra.extensions.NFSeedProvider . Configurations Ports priam.storage.port : Cassandra storage/cluster communication port. Default: 7000 . priam.ssl.storage.port : Cassandra SSL enabled storage/cluster communication port. Default: 7001 . priam.thrift.port : Cassandra thrift(pre-CQL) port for clients to connect to. Default: 9160 . priam.nativeTransport.port : Cassandra native transport port for clients to connect to (CQL). Default: 9042 . priam.jmx.port : Cassandra JMX port. Priam uses JMX to connect to local Cassandra to automate various management functions. Default: 7199 Cassandra priam.thrift.enabled : Should thrift protocol be enabled on cassandra? This is deprecated in Apache Cassandra going forward (4.x and above). Default: true in 3.x branch, else false . priam.nativeTransport.enabled : Should native protocol be enabled on cassandra. This is preferred approach. Default: true priam.endpoint_snitch : Snitch to be used by Cassandra to identify the other Cassandra instances. This depends on the environment and deployment topology of Cassandra. Example: for multi-region cluster this should be EC2MultiRegionSnitch . Default: org.apache.cassandra.locator.Ec2Snitch . This assumes an AWS hosted, single region cluster deployment. priam.compaction.throughput : Compaction throughput allowed in MB/sec for Cassandra. Default: 8 priam.partitioner : Partitioner algorithm to be used by Cassandra to hash the data. Default: org.apache.cassandra.dht.RandomPartitioner for 3.x and 3.11 branch. Note : org.apache.cassandra.dht.Murmur3Partitioner has better performance and will be default going forward. priam.streaming.throughput.mb : Streaming throughput outbound in MB/sec for Cassandra. Default: 400 . priam.internodeCompression : Compression to use by Cassandra while communicating? Allowed values are - all, dc, none. Default: all . priam.dsnitchEnabled : Enable dynamic snitch while serving the traffic? Default: true . priam.tombstone.warning.threshold : Cassandra will log warning messages in cassandra logs if a read encounters more than this value of tombstones. Default: 1000 . priam.tombstone.failure.threshold : Cassandra should fail the read if it encounters more than this value of tombstones in a single read operation. Default: 100000 . priam.streaming.socket.timeout.ms : Streaming socket timeout for Cassandra in milliseconds. Default: 86400000 (1 day). priam.compaction.large.partition.warn.threshold : Log warning message in Cassandra logs if it encounters large partitions more than this value (in MB) during compaction. Default: 100 . Cassandra Directory Configurations priam.cass.home : Directory location of the cassandra home. Default: \\etc\\cassandra . priam.cache.location : Directory location of the cassandra cache location. Default: \\var\\lib\\cassandra\\saved_caches . priam.commitlog.location : Directory location of the cassandra commitlog. Ensure Priam has read/write permissions to this folder. Default: \\var\\lib\\cassandra\\commitlog . priam.data.location : Directory location of the cassandra data folder. Ensure Priam has read/write permissions to this folder. Default: \\var\\lib\\cassandra\\data . priam.logs.location : Directory location of the cassandra logs. Default: \\var\\lib\\cassandra\\logs . priam.cass.startscript : Location (with parameters) of the cassandra start script. Default: \\etc\\init.d\\cassandra start priam.cass.stopscript : Location (with parameters) of the cassandra stop script. Default: \\etc\\init.d\\cassandra stop Cassandra JVM Configurations priam..heap.size.$INSTANCETYPE priam.heap.newgen.size.$INSTANCETYPE priam.direct.memory.size.$INSTANCETYPE JVM Options Tuning Cassandra 3.0.x added a new way to configure heap sizes and pass other JVM parameters (via jvm.options). Priam now supports configuring common options like heap setting and choosing Garbage Collection type (G1GC/CMS) natively. Default being CMS. It logs jvm.options after tuning them. Configuration priam.jvm.options.location : The file mentioned by this is used as a template and the final location where jvm.options is read and written so Cassandra can pick it for its use. Default value is {$CASS_HOME}/conf/jvm.options . Note that {$CASS_HOME} can be configured by using priam.cass.home . priam.gc.type : This is used to configure the garbage collection type for Cassandra to use. The value is an enum of G1GC or CMS . The default value is CMS . NOTE: This only comments or uncomments any configuration mentioned in provided jvm.options file. priam.jvm.options.upsert : This configuration is comma separated list of JVM options to be appended or updated (change default value) mentioned in jvm.options . Note that JVM parameters are case-sensitive and thus this configuration can only exclude JVM parameters if case match. Example: -Dsample=1,-Dsample2,-Xmn20G priam.jvm.options.exclude : This configuration is comma separated list of JVM options to be excluded which are mentioned in jvm.options . Note that JVM parameters are case-sensitive and thus this configuration can only exclude JVM parameters if case match. Exclude list is always applied after priam.jvm.options.upsert . Example: -XX:+PrintHeapAtGC,-XX:+UseParNewGC Security Configurations Priam allows to manage Cassandra security features like authentication, authorization, client SSL etc. Please refer to doc to see how to enable authorization and authentication in Cassandra. Priam uses local JMX Connection to connect to local Cassandra to automate various cluster management operations. Priam allows these JMX connections to be protected via username/password for extra security. Configurations priam.client.sslEnabled : Use SSL when clients connect to Cassandra. Default: false . priam.internodeEncryption : Use encryption when cassandra connects to other instances. Default: none priam.jmx.username : Username to use when connecting to local cassandra. Default: empty . priam.jmx.password : Password to use when connecting to local cassandra. Default: empty . priam.jmx.remote.enable : Enable the local JMX connection to be available remotely. Enabling this is not recommended as it poses security threat. Default: false .","title":"Cassandra Tuning"},{"location":"latest/mgmt/cassandratuning/#cassandra-tuning","text":"Priam tunes common cassandra configurations out of the box. Priam traditionally had support to tune Datastax Cassandra . With Datastax forking the Cassandra, Priam has stopped maintaining the DSE tuners since 3.11 branch of Priam. Note : DSE tuners will not be available going forward. Apache Cassandra 3.0.x (and above) have additional files that can be configured like jvm.options .","title":"Cassandra Tuning"},{"location":"latest/mgmt/cassandratuning/#seed-provider","text":"Priam provides its own Seed Provider for Cassandra: NFSeedProvider . This allows Cassandra to get list of seed nodes from Priam at every startup. Priam sends an updated list of instances which can be used as seed for Cassandra to bootstrap . Priam manages the bootstrap process of cassandra based on: This is a new cluster Replacement of the instance Doubling of Cassandra cluster Restore mode. priam.seed.provider : Seed provider to be used to determine the seed nodes for an instance to bootstrap. Default: com.netflix.priam.cassandra.extensions.NFSeedProvider .","title":"Seed Provider"},{"location":"latest/mgmt/cassandratuning/#configurations","text":"","title":"Configurations"},{"location":"latest/mgmt/cassandratuning/#ports","text":"priam.storage.port : Cassandra storage/cluster communication port. Default: 7000 . priam.ssl.storage.port : Cassandra SSL enabled storage/cluster communication port. Default: 7001 . priam.thrift.port : Cassandra thrift(pre-CQL) port for clients to connect to. Default: 9160 . priam.nativeTransport.port : Cassandra native transport port for clients to connect to (CQL). Default: 9042 . priam.jmx.port : Cassandra JMX port. Priam uses JMX to connect to local Cassandra to automate various management functions. Default: 7199","title":"Ports"},{"location":"latest/mgmt/cassandratuning/#cassandra","text":"priam.thrift.enabled : Should thrift protocol be enabled on cassandra? This is deprecated in Apache Cassandra going forward (4.x and above). Default: true in 3.x branch, else false . priam.nativeTransport.enabled : Should native protocol be enabled on cassandra. This is preferred approach. Default: true priam.endpoint_snitch : Snitch to be used by Cassandra to identify the other Cassandra instances. This depends on the environment and deployment topology of Cassandra. Example: for multi-region cluster this should be EC2MultiRegionSnitch . Default: org.apache.cassandra.locator.Ec2Snitch . This assumes an AWS hosted, single region cluster deployment. priam.compaction.throughput : Compaction throughput allowed in MB/sec for Cassandra. Default: 8 priam.partitioner : Partitioner algorithm to be used by Cassandra to hash the data. Default: org.apache.cassandra.dht.RandomPartitioner for 3.x and 3.11 branch. Note : org.apache.cassandra.dht.Murmur3Partitioner has better performance and will be default going forward. priam.streaming.throughput.mb : Streaming throughput outbound in MB/sec for Cassandra. Default: 400 . priam.internodeCompression : Compression to use by Cassandra while communicating? Allowed values are - all, dc, none. Default: all . priam.dsnitchEnabled : Enable dynamic snitch while serving the traffic? Default: true . priam.tombstone.warning.threshold : Cassandra will log warning messages in cassandra logs if a read encounters more than this value of tombstones. Default: 1000 . priam.tombstone.failure.threshold : Cassandra should fail the read if it encounters more than this value of tombstones in a single read operation. Default: 100000 . priam.streaming.socket.timeout.ms : Streaming socket timeout for Cassandra in milliseconds. Default: 86400000 (1 day). priam.compaction.large.partition.warn.threshold : Log warning message in Cassandra logs if it encounters large partitions more than this value (in MB) during compaction. Default: 100 .","title":"Cassandra"},{"location":"latest/mgmt/cassandratuning/#cassandra-directory-configurations","text":"priam.cass.home : Directory location of the cassandra home. Default: \\etc\\cassandra . priam.cache.location : Directory location of the cassandra cache location. Default: \\var\\lib\\cassandra\\saved_caches . priam.commitlog.location : Directory location of the cassandra commitlog. Ensure Priam has read/write permissions to this folder. Default: \\var\\lib\\cassandra\\commitlog . priam.data.location : Directory location of the cassandra data folder. Ensure Priam has read/write permissions to this folder. Default: \\var\\lib\\cassandra\\data . priam.logs.location : Directory location of the cassandra logs. Default: \\var\\lib\\cassandra\\logs . priam.cass.startscript : Location (with parameters) of the cassandra start script. Default: \\etc\\init.d\\cassandra start priam.cass.stopscript : Location (with parameters) of the cassandra stop script. Default: \\etc\\init.d\\cassandra stop","title":"Cassandra Directory Configurations"},{"location":"latest/mgmt/cassandratuning/#cassandra-jvm-configurations","text":"priam..heap.size.$INSTANCETYPE priam.heap.newgen.size.$INSTANCETYPE priam.direct.memory.size.$INSTANCETYPE","title":"Cassandra JVM Configurations"},{"location":"latest/mgmt/cassandratuning/#jvm-options-tuning","text":"Cassandra 3.0.x added a new way to configure heap sizes and pass other JVM parameters (via jvm.options). Priam now supports configuring common options like heap setting and choosing Garbage Collection type (G1GC/CMS) natively. Default being CMS. It logs jvm.options after tuning them.","title":"JVM Options Tuning"},{"location":"latest/mgmt/cassandratuning/#configuration","text":"priam.jvm.options.location : The file mentioned by this is used as a template and the final location where jvm.options is read and written so Cassandra can pick it for its use. Default value is {$CASS_HOME}/conf/jvm.options . Note that {$CASS_HOME} can be configured by using priam.cass.home . priam.gc.type : This is used to configure the garbage collection type for Cassandra to use. The value is an enum of G1GC or CMS . The default value is CMS . NOTE: This only comments or uncomments any configuration mentioned in provided jvm.options file. priam.jvm.options.upsert : This configuration is comma separated list of JVM options to be appended or updated (change default value) mentioned in jvm.options . Note that JVM parameters are case-sensitive and thus this configuration can only exclude JVM parameters if case match. Example: -Dsample=1,-Dsample2,-Xmn20G priam.jvm.options.exclude : This configuration is comma separated list of JVM options to be excluded which are mentioned in jvm.options . Note that JVM parameters are case-sensitive and thus this configuration can only exclude JVM parameters if case match. Exclude list is always applied after priam.jvm.options.upsert . Example: -XX:+PrintHeapAtGC,-XX:+UseParNewGC","title":"Configuration"},{"location":"latest/mgmt/cassandratuning/#security-configurations","text":"Priam allows to manage Cassandra security features like authentication, authorization, client SSL etc. Please refer to doc to see how to enable authorization and authentication in Cassandra. Priam uses local JMX Connection to connect to local Cassandra to automate various cluster management operations. Priam allows these JMX connections to be protected via username/password for extra security.","title":"Security Configurations"},{"location":"latest/mgmt/cassandratuning/#configurations_1","text":"priam.client.sslEnabled : Use SSL when clients connect to Cassandra. Default: false . priam.internodeEncryption : Use encryption when cassandra connects to other instances. Default: none priam.jmx.username : Username to use when connecting to local cassandra. Default: empty . priam.jmx.password : Password to use when connecting to local cassandra. Default: empty . priam.jmx.remote.enable : Enable the local JMX connection to be available remotely. Enabling this is not recommended as it poses security threat. Default: false .","title":"Configurations"},{"location":"latest/mgmt/compaction/","text":"Compaction Compact the data in SSTables on 1:* keyspaces/CF. Configuration priam.compaction.cf.include : Column Family(ies), comma delimited, to start compactions (user-initiated or on CRON). If no override exists, all keyspaces (EXCLUDING system) will be compacted. The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Compaction exclude list is applied first to exclude CF/keyspace and then compaction include list is applied to include the CF's/keyspaces. Default: None priam.compaction.cf.exclude : Column Family(ies), comma delimited, to ignore while doing compactions (user-initiated or on CRON). The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Compaction exclude list is applied first to exclude CF/keyspace and then compaction include list is applied to include the CF's/keyspaces. Default: None priam.compaction.cron : This allows compactions to be run on CRON. Example: you want to run compaction every 1 hour. Value needs to be a valid CRON expression. To disable compaction, remove any overrides i.e. return -1 for this value. The default value is -1 . API http://localhost:8080/Priam/REST/v1/cassadmin/compcat Output: For success, the payload is {\"Compcated\":true} For failure, the payload will be {\"status\":\"ERROR\", \"desc\":\"error_reason\"}","title":"Compaction"},{"location":"latest/mgmt/compaction/#compaction","text":"Compact the data in SSTables on 1:* keyspaces/CF.","title":"Compaction"},{"location":"latest/mgmt/compaction/#configuration","text":"priam.compaction.cf.include : Column Family(ies), comma delimited, to start compactions (user-initiated or on CRON). If no override exists, all keyspaces (EXCLUDING system) will be compacted. The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Compaction exclude list is applied first to exclude CF/keyspace and then compaction include list is applied to include the CF's/keyspaces. Default: None priam.compaction.cf.exclude : Column Family(ies), comma delimited, to ignore while doing compactions (user-initiated or on CRON). The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Compaction exclude list is applied first to exclude CF/keyspace and then compaction include list is applied to include the CF's/keyspaces. Default: None priam.compaction.cron : This allows compactions to be run on CRON. Example: you want to run compaction every 1 hour. Value needs to be a valid CRON expression. To disable compaction, remove any overrides i.e. return -1 for this value. The default value is -1 .","title":"Configuration"},{"location":"latest/mgmt/compaction/#api","text":"http://localhost:8080/Priam/REST/v1/cassadmin/compcat Output: For success, the payload is {\"Compcated\":true} For failure, the payload will be {\"status\":\"ERROR\", \"desc\":\"error_reason\"}","title":"API"},{"location":"latest/mgmt/configuration/","text":"Configuration Priam exposes multiple configuration via IConfiguration.java . You can choose to override the defaults configuration used by Priam by specifying properties. The defaults provided on this page are implemented by PriamConfiguration.java class. Priam has several ConfigSource bindings. The ordering of these ConfigSources determines how Priam will resolve the properties for a given instance. These sources also allow other config sources to be attached. Priam by default ships with hookup for SimpleDB as the ConfigSource. PriamConfiguration looks for properties specified in the PriamProperties SimpleDB domain. To create a property, create an item with the following attributes (the item name is not important, but it may be beneficial to set it to cluster name + property name ): appId : Your cluster name property : Name of the property * value : Property value Cluster name is inferred from your ASG name( my_cluster ). Multi zone clusters should have ASG suffixed with a zone identifier '-{zone}' ( my_cluster-useast1a ), i.e., {clustername}-{zone}. Example: If you want to change the jmx port to 7200 for your cluster 'my_cluster', create the item: Item name : my_clusterpriam.jmx.port appId : my_cluster property : priam.jmx.port value : 7200 API Priam exposes all the configuration items used to configure various components in Priam via REST API. Get all configurations http://localhost:8080/Priam/REST/v1/config/structured/group This returns all the configuration as resolved by Priam in a JSON blob. Get a configuration http://localhost:8080/Priam/REST/v1/config/structured/group/{name} This will return the configuration (as JSON) as resolved by Priam. Note : This requires the caller to know the name of the java functions, and is thus not recommended. Example for success : curl http://localhost:8080/Priam/REST/v1/config/structured/group/dynamicSnitchEnabled { dynamicSnitchEnabled :true} In case of failure : { message : No such structured config: [queueSize] } Configuration dump to local file Priam also dumps these resolved configurations (from multiple ConfigSource) into a local file at regular intervals (default: 1 min) so that any other tool using Priam can consume these configurations. Note : Priam by default changes the permission of this file so non Priam users cannot read it, as configurations may contain sensitive information. Configuration priam.configMerge.cron : Cron expression to get the resolved configurations dumped to local file. Default: 0 * * * * ? * (1 minute). priam.configMerge.dir : Directory where to dump the resolved configurations. Default: /tmp/priam_configuration .","title":"Configuration"},{"location":"latest/mgmt/configuration/#configuration","text":"Priam exposes multiple configuration via IConfiguration.java . You can choose to override the defaults configuration used by Priam by specifying properties. The defaults provided on this page are implemented by PriamConfiguration.java class. Priam has several ConfigSource bindings. The ordering of these ConfigSources determines how Priam will resolve the properties for a given instance. These sources also allow other config sources to be attached. Priam by default ships with hookup for SimpleDB as the ConfigSource. PriamConfiguration looks for properties specified in the PriamProperties SimpleDB domain. To create a property, create an item with the following attributes (the item name is not important, but it may be beneficial to set it to cluster name + property name ): appId : Your cluster name property : Name of the property * value : Property value Cluster name is inferred from your ASG name( my_cluster ). Multi zone clusters should have ASG suffixed with a zone identifier '-{zone}' ( my_cluster-useast1a ), i.e., {clustername}-{zone}. Example: If you want to change the jmx port to 7200 for your cluster 'my_cluster', create the item: Item name : my_clusterpriam.jmx.port appId : my_cluster property : priam.jmx.port value : 7200","title":"Configuration"},{"location":"latest/mgmt/configuration/#api","text":"Priam exposes all the configuration items used to configure various components in Priam via REST API.","title":"API"},{"location":"latest/mgmt/configuration/#get-all-configurations","text":"http://localhost:8080/Priam/REST/v1/config/structured/group This returns all the configuration as resolved by Priam in a JSON blob.","title":"Get all configurations"},{"location":"latest/mgmt/configuration/#get-a-configuration","text":"http://localhost:8080/Priam/REST/v1/config/structured/group/{name} This will return the configuration (as JSON) as resolved by Priam. Note : This requires the caller to know the name of the java functions, and is thus not recommended. Example for success : curl http://localhost:8080/Priam/REST/v1/config/structured/group/dynamicSnitchEnabled { dynamicSnitchEnabled :true} In case of failure : { message : No such structured config: [queueSize] }","title":"Get a configuration"},{"location":"latest/mgmt/configuration/#configuration-dump-to-local-file","text":"Priam also dumps these resolved configurations (from multiple ConfigSource) into a local file at regular intervals (default: 1 min) so that any other tool using Priam can consume these configurations. Note : Priam by default changes the permission of this file so non Priam users cannot read it, as configurations may contain sensitive information.","title":"Configuration dump to local file"},{"location":"latest/mgmt/configuration/#configuration_1","text":"priam.configMerge.cron : Cron expression to get the resolved configurations dumped to local file. Default: 0 * * * * ? * (1 minute). priam.configMerge.dir : Directory where to dump the resolved configurations. Default: /tmp/priam_configuration .","title":"Configuration"},{"location":"latest/mgmt/contributions/","text":"Contributing to Priam First off, thanks for taking the time to contribute! The following is a set of guidelines for contributing to Priam on GitHub. These are mostly guidelines, not rules. Use your best judgment, and feel free to propose changes to this document in a pull request. Table Of Contents Questions How Can I Contribute? * Reporting Bugs * Suggesting Enhancements * Your First Code Contribution * Pull Requests Questions Please feel free to file an issue on github repo, if one is not already covered in this documentation. How Can I Contribute? Reporting Bugs This section guides you through submitting a bug report for Priam. Following these guidelines helps maintainers and the community understand your report, reproduce the behavior, and find related reports. Before creating bug reports, please check this list as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible . Fill out the required template , the information it asks for helps us resolve issues faster. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one. Before Submitting A Bug Report Check if you can reproduce the problem [in the latest version of Priam. Check the FAQs on the forum for a list of common questions and problems. Perform a search to see if the problem has already been reported. If it has and the issue is still open , add a comment to the existing issue instead of opening a new one. How Do I Submit A (Good) Bug Report? Bugs are tracked as GitHub issues . Create an issue and provide the following information by filling in the template . Explain the problem and include additional details to help maintainers reproduce the problem: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. If you're providing snippets in the issue, use Markdown code blocks . Explain which behavior you expected to see instead and why. Version of the Priam and Cassandra used Did the problem start happening recently (e.g. after updating to a new version of Priam or Cassandra) or was this always a problem? Suggesting Enhancements Enhancement suggestions are tracked as GitHub issues and filling out the template Your First Code Contribution Unsure where to begin contributing to Priam? You can start by looking through these beginner and help-wanted issues. Pull Requests Please follow these steps to have your contribution considered by the maintainers: 1. Priam uses google java styling to maintain the project. Ensure that your code adheres to that. 2. Ensure that your code has all the comments at appropriate places describing the (chagne in) behavior. 3. Ensure that your code has good java documentation. 4. After you submit your pull requests, verify that all status checks are passing on Travis CI.","title":"Contributing to Priam"},{"location":"latest/mgmt/contributions/#contributing-to-priam","text":"First off, thanks for taking the time to contribute! The following is a set of guidelines for contributing to Priam on GitHub. These are mostly guidelines, not rules. Use your best judgment, and feel free to propose changes to this document in a pull request.","title":"Contributing to Priam"},{"location":"latest/mgmt/contributions/#table-of-contents","text":"Questions How Can I Contribute? * Reporting Bugs * Suggesting Enhancements * Your First Code Contribution * Pull Requests","title":"Table Of Contents"},{"location":"latest/mgmt/contributions/#questions","text":"Please feel free to file an issue on github repo, if one is not already covered in this documentation.","title":"Questions"},{"location":"latest/mgmt/contributions/#how-can-i-contribute","text":"","title":"How Can I Contribute?"},{"location":"latest/mgmt/contributions/#reporting-bugs","text":"This section guides you through submitting a bug report for Priam. Following these guidelines helps maintainers and the community understand your report, reproduce the behavior, and find related reports. Before creating bug reports, please check this list as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible . Fill out the required template , the information it asks for helps us resolve issues faster. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one.","title":"Reporting Bugs"},{"location":"latest/mgmt/contributions/#before-submitting-a-bug-report","text":"Check if you can reproduce the problem [in the latest version of Priam. Check the FAQs on the forum for a list of common questions and problems. Perform a search to see if the problem has already been reported. If it has and the issue is still open , add a comment to the existing issue instead of opening a new one.","title":"Before Submitting A Bug Report"},{"location":"latest/mgmt/contributions/#how-do-i-submit-a-good-bug-report","text":"Bugs are tracked as GitHub issues . Create an issue and provide the following information by filling in the template . Explain the problem and include additional details to help maintainers reproduce the problem: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. If you're providing snippets in the issue, use Markdown code blocks . Explain which behavior you expected to see instead and why. Version of the Priam and Cassandra used Did the problem start happening recently (e.g. after updating to a new version of Priam or Cassandra) or was this always a problem?","title":"How Do I Submit A (Good) Bug Report?"},{"location":"latest/mgmt/contributions/#suggesting-enhancements","text":"Enhancement suggestions are tracked as GitHub issues and filling out the template","title":"Suggesting Enhancements"},{"location":"latest/mgmt/contributions/#your-first-code-contribution","text":"Unsure where to begin contributing to Priam? You can start by looking through these beginner and help-wanted issues.","title":"Your First Code Contribution"},{"location":"latest/mgmt/contributions/#pull-requests","text":"Please follow these steps to have your contribution considered by the maintainers: 1. Priam uses google java styling to maintain the project. Ensure that your code adheres to that. 2. Ensure that your code has all the comments at appropriate places describing the (chagne in) behavior. 3. Ensure that your code has good java documentation. 4. After you submit your pull requests, verify that all status checks are passing on Travis CI.","title":"Pull Requests"},{"location":"latest/mgmt/flush/","text":"Flush Flush the data in Memtables on 1:* keyspaces from memory to disk Configuration priam.flush.keyspaces : To flush specific keyspaces, set property and provide a comma-delimited list of values (e.g. perftest,dse_system). If no override exists, all keyspaces (EXCLUDING system) will be flushed. Default: None priam.flush.schedule.type : This allows you to choose between 2 supported schedule types (CRON or HOUR) for the flush. The default value is HOUR . CRON : This allows flush to run on CRON and it expects either a valid value of priam.flush.cron or no override(null) to be there. If not, priam will not start and fail fast. Deprecated HOUR : This allows flush to run either on a daily basis at a given hour or hourly at a certain minute. It expects either a valid value of priam.flush.interval or no override(null) to be there. If not, priam will not start and fail fast. priam.flush.cron : This allows flush to be run on CRON. Example: you want to run flush every 15 minutes. Value needs to be a valid CRON expression. To disable flush, remove any overrides i.e. return \"-1\" for this value. The default value is -1 . Deprecated : priam.flush.interval : Set this property to specify the interval between flushes. The value is a name=value where name is an enum of hour or daily . Default: None hour means the flush will run at every hour. The value is an integer representing the minute. E.g. hour=0 will run on the hour, every hour. daily means the flush will run once daily at the specified time. The value is an integer representing the hour. E.g. daily=10 will run at 10:00 a.m. daily. API http://localhost:8080/Priam/REST/v1/cassadmin/flush Output: For success, the payload is {\"Flushed\":true} For failure, the payload will be {\"status\":\"ERROR\", \"desc\":\"error_reason\"}","title":"Flush"},{"location":"latest/mgmt/flush/#flush","text":"Flush the data in Memtables on 1:* keyspaces from memory to disk","title":"Flush"},{"location":"latest/mgmt/flush/#configuration","text":"priam.flush.keyspaces : To flush specific keyspaces, set property and provide a comma-delimited list of values (e.g. perftest,dse_system). If no override exists, all keyspaces (EXCLUDING system) will be flushed. Default: None priam.flush.schedule.type : This allows you to choose between 2 supported schedule types (CRON or HOUR) for the flush. The default value is HOUR . CRON : This allows flush to run on CRON and it expects either a valid value of priam.flush.cron or no override(null) to be there. If not, priam will not start and fail fast. Deprecated HOUR : This allows flush to run either on a daily basis at a given hour or hourly at a certain minute. It expects either a valid value of priam.flush.interval or no override(null) to be there. If not, priam will not start and fail fast. priam.flush.cron : This allows flush to be run on CRON. Example: you want to run flush every 15 minutes. Value needs to be a valid CRON expression. To disable flush, remove any overrides i.e. return \"-1\" for this value. The default value is -1 . Deprecated : priam.flush.interval : Set this property to specify the interval between flushes. The value is a name=value where name is an enum of hour or daily . Default: None hour means the flush will run at every hour. The value is an integer representing the minute. E.g. hour=0 will run on the hour, every hour. daily means the flush will run once daily at the specified time. The value is an integer representing the hour. E.g. daily=10 will run at 10:00 a.m. daily.","title":"Configuration"},{"location":"latest/mgmt/flush/#api","text":"http://localhost:8080/Priam/REST/v1/cassadmin/flush Output: For success, the payload is {\"Flushed\":true} For failure, the payload will be {\"status\":\"ERROR\", \"desc\":\"error_reason\"}","title":"API"},{"location":"latest/mgmt/health/","text":"Health Priam being the sidecar to Cassandra, monitors the health of local Cassandra. It allows user to poll for the health of Cassandra and take actions. Priam also allows user to configure to auto-start Cassandra, when Priam detects it is down. This is helpful so when Cassandra gets Out Of Memory (OOM) for any reason, Priam can simply re-start the process reducing the time to recovery. Configuration priam.remediate.dead.cassandra.rate : int representing how often (in seconds) Priam should auto-remediate Cassandra process crash If zero, Priam will restart Cassandra whenever it notices it is crashed If a positive number, Priam will restart cassandra no more than once in that number of seconds. For example a value of 60 means that Priam will only restart Cassandra once per 60 seconds If a negative number, Priam will not restart Cassandra due to crash at all. Default: 3600 (once per hour)","title":"Health"},{"location":"latest/mgmt/health/#health","text":"Priam being the sidecar to Cassandra, monitors the health of local Cassandra. It allows user to poll for the health of Cassandra and take actions. Priam also allows user to configure to auto-start Cassandra, when Priam detects it is down. This is helpful so when Cassandra gets Out Of Memory (OOM) for any reason, Priam can simply re-start the process reducing the time to recovery.","title":"Health"},{"location":"latest/mgmt/health/#configuration","text":"priam.remediate.dead.cassandra.rate : int representing how often (in seconds) Priam should auto-remediate Cassandra process crash If zero, Priam will restart Cassandra whenever it notices it is crashed If a positive number, Priam will restart cassandra no more than once in that number of seconds. For example a value of 60 means that Priam will only restart Cassandra once per 60 seconds If a negative number, Priam will not restart Cassandra due to crash at all. Default: 3600 (once per hour)","title":"Configuration"},{"location":"latest/mgmt/installation/","text":"Installation Priam provides several default implementations (AWS, Configuration, credentials etc). You can use these or choose to create your own. Build the code Set up your auto-scale group (ASG) and spin up instances Install Cassandra and web container (such as tomcat) on your instances. Setup aws credentials and SimpleDB properties Create S3 buckets to store your backups Copy priam-cass-extensions- .jar into your $CASS_HOME/lib directory Add -javaagent: $CASS_HOME/lib/priam-cass-extensions- version .jar to cassandra's JVM arguments Configure basic configurations Deploy Priam.war in your container Build Process Checkout the code from git and run: /gradlew build The gradlew script will pull down all necessary gradle components/infrastructure automatically, then run the build. This should create both a jar and a war file for your project. Note that, the default provided log4j.properties assumes tomcat deployment. Modify this according to your needs. Priam uses Google Guice. You can override several of the default implementations and bind your implementations in the provided Guice module (see PriamGuiceModule.java) Auto Scaling Group setup When setting up ASG, using as-create-auto-scaling-group, set availability zone to single zone (--availability-zones). For high availability, set multiple ASGs with one zone per ASG. Choosing ASG name Your Cassandra cluster could be spanning multiple ASGs. Such cases arise when you want to provide HA across zones and to overcome the AWS limitation of load balancing across zones i.e., currently, AWS does not guarantee instances will be balanced across zones if instances are not available in a particular zone. In such cases, you could create multiple ASGs with each ASG bound to single zone. In such cases your ASG name should be suffixed with '-{ZONE}' . Eg: test_cluster-useast1a. Web Container setup Since Priam changes the configuration files for Cassandra and starts/stops the services, the web container it's running in must have execute rights on the script to modify the cassandra.yaml file and execute the /etc/init.d/cassandra (configurable location) script. Credentials The default implementation uses clear text credentials. To use this provide AWS accessid and secrectkey in -/etc/awscredential.properties -- copy and modify from src/main/resources/conf/awscredential.properties . You can however, override ICredential to provide a more secure way of obtaining credentials. Additionally, ensure your keys do not contain special characters and are not enclosed in quotes of any kind. The preferred way is to use IAM key profile management. IAMCredential Using IAM Credentials allows you to provide access to the AWS api without storing an AccessKeyId or SecretAccessKey anywhere on the machine. Create a new IAM Role in the AWS console or using the API and make sure it can access EC2, S3, and SimpleDB resources. Assign that role to the auto scaling group. Modify priam/src/main/java/com/netflix/priam/defaultimpl/PriamGuiceModule.java ```java // Add this line import com.netflix.priam.aws.IAMCredential; public class PriamGuiceModule extends AbstractModule { bind(IBackupFileSystem.class).annotatedWith(Names.named(\"backup\")).to(S3FileSystem.class); bind(IBackupFileSystem.class).annotatedWith(Names.named(\"incr_restore\")).to(S3FileSystem.class); bind(IBackupFileSystem.class).annotatedWith(Names.named(\"backup_status\")).to(S3FileSystem.class); ..... // Add this line bind(ICredential.class).to(IAMCredential.class); } ``` S3 Buckets Create an S3 bucket to store your backup files. The default bucket name used by PriamConfiguration is cassandra-archive. Ensure the Credentials used above has permissions to read/write to this S3 bucket. For best performance (and cost), consider creating one S3 bucket per AWS region. SimpleDB Domains Priam uses SimpleDB to register nodes as well as read properties. Create the following SimpleDB domains: InstanceIdentity PriamProperties. Use PriamProperties to add properties if you want to modify defaults. InstanceIdentity is used by Priam to register nodes. The SimpleDB domains must be located in the US-East-1 region. Note : SimpleDB Configuration Management and Token Management is soon to be deprecated and moved to use DynamoDB. PriamStartupAgent and NFSeedProvider These are the 2 classes that will be required by Cassandra for starting and fetching token, seeds and other information from Priam. You will need to copy priam-cass-extensions- .jar into your $CASS_HOME/lib directory, and add -javaagent:$CASS_HOME/lib/priam-cass-extensions- .jar to cassandra's JVM arguments. Priam updates cassandra.yaml with NFSeedProvider by default. Configuration To change the default Priam properties, you can create property items in the PriamProperties SimpleDB domain. Each property item is defined by the attributes appId, property and value. appId is set to the ASG name by default. When using multiple ASGs, the zone suffix is removed. Refer above for ASG naming convention. Refer to Properties for property name and default value for all property items. Providing start and stop scripts Configure the name of the application. As part of the configuration provide any custom start and stop scripts to Priam via properties. PriamConfiguration defaults to /etc/init.d/cassandra script for starting and stopping. Deploying Copy the jar generated in the build step into the cassandra lib directory. Deploy the war into your web container. Verification To see if Priam has started successfully, you can lookup SimpleDB InstanceIdentity domain for entries for the ASG. Each entry will have instanceid, hostname, token and other details used by the particular node. You can also verify REST API by running: $curl http://localhost:8080/Priam/REST/v1/cassconfig/get_token This should return the token used by node. Kudos if you reached so far! Ensure your Cassandra process is up and is using the same token found by running the above command.","title":"Installation"},{"location":"latest/mgmt/installation/#installation","text":"Priam provides several default implementations (AWS, Configuration, credentials etc). You can use these or choose to create your own. Build the code Set up your auto-scale group (ASG) and spin up instances Install Cassandra and web container (such as tomcat) on your instances. Setup aws credentials and SimpleDB properties Create S3 buckets to store your backups Copy priam-cass-extensions- .jar into your $CASS_HOME/lib directory Add -javaagent: $CASS_HOME/lib/priam-cass-extensions- version .jar to cassandra's JVM arguments Configure basic configurations Deploy Priam.war in your container","title":"Installation"},{"location":"latest/mgmt/installation/#build-process","text":"Checkout the code from git and run: /gradlew build The gradlew script will pull down all necessary gradle components/infrastructure automatically, then run the build. This should create both a jar and a war file for your project. Note that, the default provided log4j.properties assumes tomcat deployment. Modify this according to your needs. Priam uses Google Guice. You can override several of the default implementations and bind your implementations in the provided Guice module (see PriamGuiceModule.java)","title":"Build Process"},{"location":"latest/mgmt/installation/#auto-scaling-group-setup","text":"When setting up ASG, using as-create-auto-scaling-group, set availability zone to single zone (--availability-zones). For high availability, set multiple ASGs with one zone per ASG.","title":"Auto Scaling Group setup"},{"location":"latest/mgmt/installation/#choosing-asg-name","text":"Your Cassandra cluster could be spanning multiple ASGs. Such cases arise when you want to provide HA across zones and to overcome the AWS limitation of load balancing across zones i.e., currently, AWS does not guarantee instances will be balanced across zones if instances are not available in a particular zone. In such cases, you could create multiple ASGs with each ASG bound to single zone. In such cases your ASG name should be suffixed with '-{ZONE}' . Eg: test_cluster-useast1a.","title":"Choosing ASG name"},{"location":"latest/mgmt/installation/#web-container-setup","text":"Since Priam changes the configuration files for Cassandra and starts/stops the services, the web container it's running in must have execute rights on the script to modify the cassandra.yaml file and execute the /etc/init.d/cassandra (configurable location) script.","title":"Web Container setup"},{"location":"latest/mgmt/installation/#credentials","text":"The default implementation uses clear text credentials. To use this provide AWS accessid and secrectkey in -/etc/awscredential.properties -- copy and modify from src/main/resources/conf/awscredential.properties . You can however, override ICredential to provide a more secure way of obtaining credentials. Additionally, ensure your keys do not contain special characters and are not enclosed in quotes of any kind. The preferred way is to use IAM key profile management.","title":"Credentials"},{"location":"latest/mgmt/installation/#iamcredential","text":"Using IAM Credentials allows you to provide access to the AWS api without storing an AccessKeyId or SecretAccessKey anywhere on the machine. Create a new IAM Role in the AWS console or using the API and make sure it can access EC2, S3, and SimpleDB resources. Assign that role to the auto scaling group. Modify priam/src/main/java/com/netflix/priam/defaultimpl/PriamGuiceModule.java ```java // Add this line import com.netflix.priam.aws.IAMCredential; public class PriamGuiceModule extends AbstractModule { bind(IBackupFileSystem.class).annotatedWith(Names.named(\"backup\")).to(S3FileSystem.class); bind(IBackupFileSystem.class).annotatedWith(Names.named(\"incr_restore\")).to(S3FileSystem.class); bind(IBackupFileSystem.class).annotatedWith(Names.named(\"backup_status\")).to(S3FileSystem.class); ..... // Add this line bind(ICredential.class).to(IAMCredential.class); } ```","title":"IAMCredential"},{"location":"latest/mgmt/installation/#s3-buckets","text":"Create an S3 bucket to store your backup files. The default bucket name used by PriamConfiguration is cassandra-archive. Ensure the Credentials used above has permissions to read/write to this S3 bucket. For best performance (and cost), consider creating one S3 bucket per AWS region.","title":"S3 Buckets"},{"location":"latest/mgmt/installation/#simpledb-domains","text":"Priam uses SimpleDB to register nodes as well as read properties. Create the following SimpleDB domains: InstanceIdentity PriamProperties. Use PriamProperties to add properties if you want to modify defaults. InstanceIdentity is used by Priam to register nodes. The SimpleDB domains must be located in the US-East-1 region. Note : SimpleDB Configuration Management and Token Management is soon to be deprecated and moved to use DynamoDB.","title":"SimpleDB Domains"},{"location":"latest/mgmt/installation/#priamstartupagent-and-nfseedprovider","text":"These are the 2 classes that will be required by Cassandra for starting and fetching token, seeds and other information from Priam. You will need to copy priam-cass-extensions- .jar into your $CASS_HOME/lib directory, and add -javaagent:$CASS_HOME/lib/priam-cass-extensions- .jar to cassandra's JVM arguments. Priam updates cassandra.yaml with NFSeedProvider by default.","title":"PriamStartupAgent and NFSeedProvider"},{"location":"latest/mgmt/installation/#configuration","text":"To change the default Priam properties, you can create property items in the PriamProperties SimpleDB domain. Each property item is defined by the attributes appId, property and value. appId is set to the ASG name by default. When using multiple ASGs, the zone suffix is removed. Refer above for ASG naming convention. Refer to Properties for property name and default value for all property items.","title":"Configuration"},{"location":"latest/mgmt/installation/#providing-start-and-stop-scripts","text":"Configure the name of the application. As part of the configuration provide any custom start and stop scripts to Priam via properties. PriamConfiguration defaults to /etc/init.d/cassandra script for starting and stopping.","title":"Providing start and stop scripts"},{"location":"latest/mgmt/installation/#deploying","text":"Copy the jar generated in the build step into the cassandra lib directory. Deploy the war into your web container.","title":"Deploying"},{"location":"latest/mgmt/installation/#verification","text":"To see if Priam has started successfully, you can lookup SimpleDB InstanceIdentity domain for entries for the ASG. Each entry will have instanceid, hostname, token and other details used by the particular node. You can also verify REST API by running: $curl http://localhost:8080/Priam/REST/v1/cassconfig/get_token This should return the token used by node. Kudos if you reached so far! Ensure your Cassandra process is up and is using the same token found by running the above command.","title":"Verification"},{"location":"latest/mgmt/metrics/","text":"Metrics Priam uses spectator to collect Metrics. The default binding is no operation. |Name|Type|Purpose| | priam.upload.rate |DistributionSummary|Rate at which Priam is uploading the files to remote file system (during backup).| | priam.upload.valid |Counter|No of successful uploads to the remote file system.| | priam.upload.invalid |Counter|No. of uploads to the remote file system which failed after exhausting all the retries.| | priam.upload.queue.size |Counter|Size of the upload queue where items are waiting to be uploaded.| | priam.download.rate |DistributionSummary|Rate at which Priam is downloading the files from remote file system (during restore).| | priam.download.valid |Counter|No of successful downloads from the remote file system.| | priam.download.invalid |Counter|No. of downloads from the remote file system which failed after exhausting all the retries.| | priam.download.queue.size |Counter|Size of the download queue where items are waiting to be downloaded.| | priam.sns.notification.success |Counter|Total number of sns notifications sent which are successful| | priam.sns.notification.failure |Counter|Total number of sns notifications which failed after exhausting all the retries (may be configuration error)| | priam.forgotten.files |Counter|No. of files that are considered forgotten by Cassandra, as detected by Priam during snapshot. Note : This is exclusive feature of 3.x (C* 2.x) branch|","title":"Metrics"},{"location":"latest/mgmt/metrics/#metrics","text":"Priam uses spectator to collect Metrics. The default binding is no operation. |Name|Type|Purpose| | priam.upload.rate |DistributionSummary|Rate at which Priam is uploading the files to remote file system (during backup).| | priam.upload.valid |Counter|No of successful uploads to the remote file system.| | priam.upload.invalid |Counter|No. of uploads to the remote file system which failed after exhausting all the retries.| | priam.upload.queue.size |Counter|Size of the upload queue where items are waiting to be uploaded.| | priam.download.rate |DistributionSummary|Rate at which Priam is downloading the files from remote file system (during restore).| | priam.download.valid |Counter|No of successful downloads from the remote file system.| | priam.download.invalid |Counter|No. of downloads from the remote file system which failed after exhausting all the retries.| | priam.download.queue.size |Counter|Size of the download queue where items are waiting to be downloaded.| | priam.sns.notification.success |Counter|Total number of sns notifications sent which are successful| | priam.sns.notification.failure |Counter|Total number of sns notifications which failed after exhausting all the retries (may be configuration error)| | priam.forgotten.files |Counter|No. of files that are considered forgotten by Cassandra, as detected by Priam during snapshot. Note : This is exclusive feature of 3.x (C* 2.x) branch|","title":"Metrics"},{"location":"latest/mgmt/presentations/","text":"","title":"Presentations"},{"location":"latest/mgmt/restore/","text":"Restore Data from a snapshot can be restored to the same cluster or a different cluster. To restore a cluster, the user specifies a start and end time for which the backup data is available. Priam executes the following sequence of steps for restoring: Search for the latest snapshot within the time range Download meta file for the snapshot Download snapshot files specified in the meta file Download all available incremental files up to the end time Execute a post restore hook if available, and wait for completion of the hook execution Start the cluster and join the ring The LocationInfo files are ignored and not backed up. This forces Cassandra to rediscover other nodes in the cluster upon restore and refresh the ring nodes. Important : Restores should only be performed on the same size cluster. Async Downloads During restore, the instance is not in service and thus Priam tries its best to utilize available bandwidth to download the SSTables from remote file system. We use 8 threads by default to download the files. Configuration priam.restore.prefix : This is the location from where the backup will be restored. This has to be the fully qualified location where cluster backup is stored (till cluster name). E.g. bucket_name/test_backup/test/us-east-1/cass_appname . Default: None priam.restore.snapshot : This is the start dateTime and end dateTime from which cluster will be restored. Priam will start finding the latest full snapshot from the end dateTime and will keep going till start dateTime. After the full snapshot is found, Priam downloads all the incremental's. E.g. 2017040500,201704092359 . Default: None priam.restore.threads : The number of threads to use for restore. Default: 8 priam.restore.cf.include : Column Family(ies), comma delimited, to include for restore. If no override exists, all keyspaces/cf's will be restored. The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Restore exclude list is applied first to exclude CF/keyspace and then restore include list is applied to include the CF's/keyspaces. Default: None priam.restore.cf.exclude : Column Family(ies), comma delimited, to ignore while doing restore. The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Restore exclude list is applied first to exclude CF/keyspace and then restore include list is applied to include the CF's/keyspaces. Default: None priam.clrestore.max : Max number of commit logs to restore. This will by default take last N number of commit logs to restore if commit log backup is enabled. Default: 10 . priam.postrestorehook.enabled : indicates if postrestorehook is enabled. priam.postrestorehook : contains the command with arguments to be executed as part of postrestorehook. Priam would wait for completion of this hook before proceeding to starting C*. priam.postrestorehook.heartbeat.filename : heartbeat file that postrestorehook emits. Priam keeps a tab on this file to make sure postrestorehook is making progress. Otherwise, a new process of postrestorehook would be spawned (upon killing existing process if still exists) priam.postrestorehook.done.filename :'done' file that postrestorehook creates upon completion of execution. priam.postrestorehook.timeout.in.days :maximum time that Priam should wait before killing the postrestorehook process (if not already complete) priam.download.queue.size : Queue size to be used for restore downloads. Note that once queue is full, we would wait for priam.download.timeout to add any new item before declining the request and throwing exception. Default: 100,000. priam.download.timeout : Downloads are scheduled in priam.download.queue.size . If queue is full then we wait for this time for the queue to have an entry available for queueing the current task. Default: 10 minutes. Support for Encrypted Backups Priam restore will handle decryption of the encrypted files. Any file downloaded from remote file system will be first decrypted and then decompressed to ephemeral disk. As part of the restore, Priam will decrypt the ciphertext to plaintext if property ( priam.encrypted.restore.enabled ) is set to true. Priam uses PGP as the encryption / decryption cryptography algorithm. Other algorithm can be implemented via interface IFileCryptography. *Note: Pgp uses a passphrase to encrypt your private key on your node. See (http://www.pgpi.org/doc/pgpintro/), section \u201cwhat is a passphrase\u201d for details. Priam restore from AWS bucket using \u201crole assumption\u201d: The use case is you are trying to restore objects created by different AWS accounts. See AWS documentation for \u201ccross account access using roles\u201d for detail information. Currently, Google cloud and secondary/cross AWS accounts are supported for restoring the encrypted backups. Configuration priam.encrypted.restore.enabled : Enable the restore where the backups are encrypted using PGP. priam.pgp.password.phrase : The passphrase used by the cryptography algorithm to encrypt/decrypt. By default, it is expected that this value will be encrypted using open encrypt. Default: None . priam.private.key.location : The location on disk of the private key used by the cryptography algorithm. priam.pgp.pubkey.file.location : The location on disk of the public key used by the cryptography algorithm. priam.restore.source.type : The type of source for the restore. Valid values: AWSCROSSACCT or GOOGLE. Default: None priam.gcs.service.acct.id : Google Cloud Storage service account id. This value is supposed to be encrypted using open encrypt. Default: None priam.gcs.service.acct.private.key : The absolute path on disk for the Google Cloud Storage PFX file (i.e. the combined format of the private key and certificate). This value is supposed to be encrypted using open encrypt. Default: None priam.roleassumption.arn : Amazon Resource Name to assume while restoring the backups from an AWS account which requires cross-account assumption. Default: None API Restore Status http://localhost:8080/Priam/REST/v1/restore/status This gives the status of the current or last restore. Note that the restore status is not persisted on ephemeral disk and thus this status may be lost at restart of Priam. Output : json { \"startDateRange\": \"[yyyyMMddHHmm]\", \"endDateRange\": \"[yyyyMMddHHmm]\", \"executionStartTime\": \"[yyyyMMddHHmm]\", \"executionEndTime\": \"[yyyyMMddHHmm]\", \"snapshotMetaFile\": \" remote_file_system_location_of_meta.json_used_for_restore \", \"status\": \"[STARTED|FINISHED|FAILED]\" } Manual Restore http://localhost:8080/Priam/REST/v1/restore/{daterange} This starts a user-triggered restore for a given daterange. Note : It expects that other restore configurations are already configured. It requires a minimum of priam.restore.prefix to be already configured. Parameters : 1. daterange : Optional: This is a comma separated start time and end time for the restore in the format of yyyyMMddHHmm or yyyyMMdd . If no value is provided or a value of default is provided then it takes start time as (current time - 1 day) and end time as current time. Output : json {\"ok\"}","title":"Restore"},{"location":"latest/mgmt/restore/#restore","text":"Data from a snapshot can be restored to the same cluster or a different cluster. To restore a cluster, the user specifies a start and end time for which the backup data is available. Priam executes the following sequence of steps for restoring: Search for the latest snapshot within the time range Download meta file for the snapshot Download snapshot files specified in the meta file Download all available incremental files up to the end time Execute a post restore hook if available, and wait for completion of the hook execution Start the cluster and join the ring The LocationInfo files are ignored and not backed up. This forces Cassandra to rediscover other nodes in the cluster upon restore and refresh the ring nodes. Important : Restores should only be performed on the same size cluster.","title":"Restore"},{"location":"latest/mgmt/restore/#async-downloads","text":"During restore, the instance is not in service and thus Priam tries its best to utilize available bandwidth to download the SSTables from remote file system. We use 8 threads by default to download the files.","title":"Async Downloads"},{"location":"latest/mgmt/restore/#configuration","text":"priam.restore.prefix : This is the location from where the backup will be restored. This has to be the fully qualified location where cluster backup is stored (till cluster name). E.g. bucket_name/test_backup/test/us-east-1/cass_appname . Default: None priam.restore.snapshot : This is the start dateTime and end dateTime from which cluster will be restored. Priam will start finding the latest full snapshot from the end dateTime and will keep going till start dateTime. After the full snapshot is found, Priam downloads all the incremental's. E.g. 2017040500,201704092359 . Default: None priam.restore.threads : The number of threads to use for restore. Default: 8 priam.restore.cf.include : Column Family(ies), comma delimited, to include for restore. If no override exists, all keyspaces/cf's will be restored. The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Restore exclude list is applied first to exclude CF/keyspace and then restore include list is applied to include the CF's/keyspaces. Default: None priam.restore.cf.exclude : Column Family(ies), comma delimited, to ignore while doing restore. The expected format is keyspace.cfname. CF name allows special character \" * \" to denote all the columnfamilies in a given keyspace. e.g. keyspace1.* denotes all the CFs in keyspace1. Restore exclude list is applied first to exclude CF/keyspace and then restore include list is applied to include the CF's/keyspaces. Default: None priam.clrestore.max : Max number of commit logs to restore. This will by default take last N number of commit logs to restore if commit log backup is enabled. Default: 10 . priam.postrestorehook.enabled : indicates if postrestorehook is enabled. priam.postrestorehook : contains the command with arguments to be executed as part of postrestorehook. Priam would wait for completion of this hook before proceeding to starting C*. priam.postrestorehook.heartbeat.filename : heartbeat file that postrestorehook emits. Priam keeps a tab on this file to make sure postrestorehook is making progress. Otherwise, a new process of postrestorehook would be spawned (upon killing existing process if still exists) priam.postrestorehook.done.filename :'done' file that postrestorehook creates upon completion of execution. priam.postrestorehook.timeout.in.days :maximum time that Priam should wait before killing the postrestorehook process (if not already complete) priam.download.queue.size : Queue size to be used for restore downloads. Note that once queue is full, we would wait for priam.download.timeout to add any new item before declining the request and throwing exception. Default: 100,000. priam.download.timeout : Downloads are scheduled in priam.download.queue.size . If queue is full then we wait for this time for the queue to have an entry available for queueing the current task. Default: 10 minutes.","title":"Configuration"},{"location":"latest/mgmt/restore/#support-for-encrypted-backups","text":"Priam restore will handle decryption of the encrypted files. Any file downloaded from remote file system will be first decrypted and then decompressed to ephemeral disk. As part of the restore, Priam will decrypt the ciphertext to plaintext if property ( priam.encrypted.restore.enabled ) is set to true. Priam uses PGP as the encryption / decryption cryptography algorithm. Other algorithm can be implemented via interface IFileCryptography. *Note: Pgp uses a passphrase to encrypt your private key on your node. See (http://www.pgpi.org/doc/pgpintro/), section \u201cwhat is a passphrase\u201d for details. Priam restore from AWS bucket using \u201crole assumption\u201d: The use case is you are trying to restore objects created by different AWS accounts. See AWS documentation for \u201ccross account access using roles\u201d for detail information. Currently, Google cloud and secondary/cross AWS accounts are supported for restoring the encrypted backups.","title":"Support for Encrypted Backups"},{"location":"latest/mgmt/restore/#configuration_1","text":"priam.encrypted.restore.enabled : Enable the restore where the backups are encrypted using PGP. priam.pgp.password.phrase : The passphrase used by the cryptography algorithm to encrypt/decrypt. By default, it is expected that this value will be encrypted using open encrypt. Default: None . priam.private.key.location : The location on disk of the private key used by the cryptography algorithm. priam.pgp.pubkey.file.location : The location on disk of the public key used by the cryptography algorithm. priam.restore.source.type : The type of source for the restore. Valid values: AWSCROSSACCT or GOOGLE. Default: None priam.gcs.service.acct.id : Google Cloud Storage service account id. This value is supposed to be encrypted using open encrypt. Default: None priam.gcs.service.acct.private.key : The absolute path on disk for the Google Cloud Storage PFX file (i.e. the combined format of the private key and certificate). This value is supposed to be encrypted using open encrypt. Default: None priam.roleassumption.arn : Amazon Resource Name to assume while restoring the backups from an AWS account which requires cross-account assumption. Default: None","title":"Configuration"},{"location":"latest/mgmt/restore/#api","text":"","title":"API"},{"location":"latest/mgmt/restore/#restore-status","text":"http://localhost:8080/Priam/REST/v1/restore/status This gives the status of the current or last restore. Note that the restore status is not persisted on ephemeral disk and thus this status may be lost at restart of Priam. Output : json { \"startDateRange\": \"[yyyyMMddHHmm]\", \"endDateRange\": \"[yyyyMMddHHmm]\", \"executionStartTime\": \"[yyyyMMddHHmm]\", \"executionEndTime\": \"[yyyyMMddHHmm]\", \"snapshotMetaFile\": \" remote_file_system_location_of_meta.json_used_for_restore \", \"status\": \"[STARTED|FINISHED|FAILED]\" }","title":"Restore Status"},{"location":"latest/mgmt/restore/#manual-restore","text":"http://localhost:8080/Priam/REST/v1/restore/{daterange} This starts a user-triggered restore for a given daterange. Note : It expects that other restore configurations are already configured. It requires a minimum of priam.restore.prefix to be already configured. Parameters : 1. daterange : Optional: This is a comma separated start time and end time for the restore in the format of yyyyMMddHHmm or yyyyMMdd . If no value is provided or a value of default is provided then it takes start time as (current time - 1 day) and end time as current time. Output : json {\"ok\"}","title":"Manual Restore"},{"location":"latest/mgmt/tokenmanagement/","text":"","title":"Tokenmanagement"},{"location":"latest/template/bug_report/","text":"Describe the bug A clear and concise description of what the bug is. To Reproduce Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error Expected behavior A clear and concise description of what you expected to happen. Screenshots If applicable, add screenshots to help explain your problem. Version Version of Priam and Cassandra used. Additional context Add any other context about the problem here.","title":"Bug report"},{"location":"latest/template/feature_request/","text":"Is your feature request related to a problem? Please describe. A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] Describe the solution you'd like A clear and concise description of what you want to happen. Describe alternatives you've considered A clear and concise description of any alternative solutions or features you've considered. Additional context Add any other context or screenshots about the feature request here.","title":"Feature request"}]}